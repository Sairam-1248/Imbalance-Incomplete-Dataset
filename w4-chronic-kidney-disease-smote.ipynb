{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2005,"sourceType":"datasetVersion","datasetId":1111},{"sourceId":7360491,"sourceType":"datasetVersion","datasetId":4275380},{"sourceId":7366942,"sourceType":"datasetVersion","datasetId":4279856},{"sourceId":7367320,"sourceType":"datasetVersion","datasetId":4280079}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sriusairam/w4-f-chronic-kidney-disease?scriptVersionId=227065251\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# 💥 Chronic Kidney Disease","metadata":{}},{"cell_type":"markdown","source":"🏆 Problem Statement: Using the data which has 25 features to predict patient with chronic kidney disease","metadata":{}},{"cell_type":"markdown","source":"# Generalized code for handling Imbalance and incomplete datasets ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Load dataset\ndf_original = pd.read_csv('/kaggle/input/kidney-modified-dataset/Kidney_dataset_Modified.csv')  # Update path accordingly\n\n# Function to introduce missing values\ndef introduce_missing_values(data, missing_percentage):\n    data = data.copy()\n    total_values = data.size\n    missing_count = int((missing_percentage / 100) * total_values)\n    indices = np.random.choice(data.size, missing_count, replace=False)\n    flat_data = data.values.flatten()\n    flat_data[indices] = np.nan\n    return pd.DataFrame(flat_data.reshape(data.shape), columns=data.columns)\n\n# Store results for different percentages of missing values\nmissing_percents = [10, 20, 30, 40, 50]\naccuracy_scores = []\nprecision_scores = []\nrecall_scores = []\nf1_scores = []\n\n# Iterate over different missing percentages\nfor missing_percentage in missing_percents:\n    print(f\"\\nEvaluating for {missing_percentage}% missing values...\")\n\n    # Introduce missing values\n    df = introduce_missing_values(df_original, missing_percentage)\n    \n    # Fill missing values with 0\n    df.fillna(0, inplace=True)\n\n    # Splitting majority and minority classes\n    majority_class = df[df['class'] == 0]\n    minority_class = df[df['class'] == 1]\n    \n    # Create 2 refined datasets\n    majority_partitions = np.array_split(majority_class, 2)\n    refined_datasets = [pd.concat([minority_class, part]) for part in majority_partitions]\n    \n    print(f\"Total Refined Datasets Created: {len(refined_datasets)}\")\n\n    # Apply fixed instance weighting\n    def assign_weights(dataset):\n        dataset['weights'] = dataset['class'].apply(lambda x: 1 if x == 1 else 0.5)\n        return dataset\n\n    refined_datasets = [assign_weights(rd) for rd in refined_datasets]\n    \n    # Display the assigned weights\n    print(f\"Assigned Weights: Minority = 1, Majority = 0.5\")\n    \n    # Generate subspace classifiers\n    def generate_subspace_classifiers(dataset, dataset_idx):\n        classifiers = []\n        features = dataset.drop(columns=['class', 'weights']).columns.tolist()\n        clf_count = 0  # Track classifier index\n\n        while features:\n            X = dataset[features]\n            y = dataset['class']\n            \n            if X.empty or y.empty:\n                print(f\"Skipping dataset {dataset_idx}: No data available.\")\n                break\n            \n            clf = DecisionTreeClassifier(\n                criterion='entropy',\n                splitter='best',\n                max_depth=6,\n                min_samples_split=4,\n                min_samples_leaf=2,\n                random_state=42,\n                class_weight='balanced'\n            )\n            clf.fit(X, y)\n            selected_features = X.columns[clf.feature_importances_ > 0].tolist()\n            \n            if not selected_features:\n                break  # Stop if no important features are found\n            \n            classifier_name = f'dt_{dataset_idx}_{clf_count}'\n            classifiers.append((classifier_name, DecisionTreeClassifier(\n                criterion='entropy',\n                splitter='best',\n                max_depth=6,\n                min_samples_split=4,\n                min_samples_leaf=2,\n                random_state=42,\n                class_weight='balanced'\n            ).fit(X[selected_features], y)))\n            \n            features = [f for f in features if f not in selected_features]\n            clf_count += 1\n\n        print(f\"Refined Dataset {dataset_idx}: {len(classifiers)} Subspace Classifiers Generated\")\n        return classifiers\n\n    all_classifiers = []\n    for idx, rd in enumerate(refined_datasets):\n        all_classifiers.extend(generate_subspace_classifiers(rd, idx))\n\n    if not all_classifiers:\n        print(f\"No classifiers generated for {missing_percentage}% missing values. Skipping evaluation.\")\n        continue\n\n    # Ensemble classifier\n    ensemble_clf = VotingClassifier(estimators=all_classifiers, voting='soft')\n    \n    try:\n        X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['class']), df['class'], test_size=0.2)\n        \n        if X_train.empty or y_train.empty:\n            print(f\"Skipping training for {missing_percentage}% missing values: No valid training data.\")\n            continue\n        \n        ensemble_clf.fit(X_train, y_train)\n        y_pred = ensemble_clf.predict(X_test)\n\n        # Compute performance metrics\n        accuracy = accuracy_score(y_test, y_pred)\n        precision = precision_score(y_test, y_pred)\n        recall = recall_score(y_test, y_pred)\n        f1 = f1_score(y_test, y_pred)\n\n        # Store results for plotting\n        accuracy_scores.append(accuracy)\n        precision_scores.append(precision)\n        recall_scores.append(recall)\n        f1_scores.append(f1)\n\n        # Display results\n        print(f\"Missing Percentage: {missing_percentage}%\")\n        print(f\"Accuracy: {accuracy:.4f}\")\n        print(f\"Precision: {precision:.4f}\")\n        print(f\"Recall: {recall:.4f}\")\n        print(f\"F1 Score: {f1:.4f}\")\n\n    except ValueError as e:\n        print(f\"Error encountered for {missing_percentage}% missing values: {e}\")\n        continue\n\n# Plot metrics vs. Missing Percentage\nplt.figure(figsize=(10, 6))\nplt.plot(missing_percents[:len(f1_scores)], accuracy_scores, marker='o', linestyle='-', label=\"Accuracy\", color='b')\nplt.plot(missing_percents[:len(f1_scores)], precision_scores, marker='s', linestyle='-', label=\"Precision\", color='g')\nplt.plot(missing_percents[:len(f1_scores)], recall_scores, marker='^', linestyle='-', label=\"Recall\", color='r')\nplt.plot(missing_percents[:len(f1_scores)], f1_scores, marker='d', linestyle='-', label=\"F1 Score\", color='purple')\n\nplt.xlabel(\"Percentage of Missing Values\")\nplt.ylabel(\"Performance Metrics\")\nplt.title(\"Impact of Missing Values on Model Performance\")\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T19:09:56.404574Z","iopub.execute_input":"2025-03-11T19:09:56.40499Z","iopub.status.idle":"2025-03-11T19:09:57.253251Z","shell.execute_reply.started":"2025-03-11T19:09:56.404927Z","shell.execute_reply":"2025-03-11T19:09:57.251991Z"}},"outputs":[{"name":"stdout","text":"\nEvaluating for 10% missing values...\nTotal Refined Datasets Created: 2\nAssigned Weights: Minority = 1, Majority = 0.5\nRefined Dataset 0: 4 Subspace Classifiers Generated\nRefined Dataset 1: 3 Subspace Classifiers Generated\nMissing Percentage: 10%\nAccuracy: 0.9167\nPrecision: 0.8846\nRecall: 0.9200\nF1 Score: 0.9020\n\nEvaluating for 20% missing values...\nTotal Refined Datasets Created: 2\nAssigned Weights: Minority = 1, Majority = 0.5\nRefined Dataset 0: 4 Subspace Classifiers Generated\nRefined Dataset 1: 3 Subspace Classifiers Generated\nMissing Percentage: 20%\nAccuracy: 0.8167\nPrecision: 0.7308\nRecall: 0.8261\nF1 Score: 0.7755\n\nEvaluating for 30% missing values...\nTotal Refined Datasets Created: 2\nAssigned Weights: Minority = 1, Majority = 0.5\nRefined Dataset 0: 3 Subspace Classifiers Generated\nRefined Dataset 1: 3 Subspace Classifiers Generated\nMissing Percentage: 30%\nAccuracy: 0.7500\nPrecision: 0.7000\nRecall: 0.6087\nF1 Score: 0.6512\n\nEvaluating for 40% missing values...\nTotal Refined Datasets Created: 2\nAssigned Weights: Minority = 1, Majority = 0.5\nRefined Dataset 0: 4 Subspace Classifiers Generated\nRefined Dataset 1: 4 Subspace Classifiers Generated\nMissing Percentage: 40%\nAccuracy: 0.7333\nPrecision: 0.6190\nRecall: 0.6190\nF1 Score: 0.6190\n\nEvaluating for 50% missing values...\nTotal Refined Datasets Created: 2\nAssigned Weights: Minority = 1, Majority = 0.5\nRefined Dataset 0: 4 Subspace Classifiers Generated\nRefined Dataset 1: 4 Subspace Classifiers Generated\nMissing Percentage: 50%\nAccuracy: 0.6833\nPrecision: 0.3846\nRecall: 0.7692\nF1 Score: 0.5128\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# OLD Experiments ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Load dataset\ndf_original = pd.read_csv('/kaggle/input/kidney-modified-dataset/Kidney_dataset_Modified.csv')  # Update path accordingly\n\n# Function to introduce missing values\ndef introduce_missing_values(data, missing_percentage):\n    data = data.copy()\n    total_values = data.size\n    missing_count = int((missing_percentage / 100) * total_values)\n    indices = np.random.choice(data.size, missing_count, replace=False)\n    flat_data = data.values.flatten()\n    flat_data[indices] = np.nan\n    return pd.DataFrame(flat_data.reshape(data.shape), columns=data.columns)\n\n# Store results for different percentages of missing values\nmissing_percents = [10, 20, 30, 40, 50]\nf1_scores = []\n\n# Iterate over different missing percentages\nfor missing_percentage in missing_percents:\n    print(f\"\\nEvaluating for {missing_percentage}% missing values...\")\n\n    # Introduce missing values\n    df = introduce_missing_values(df_original, missing_percentage)\n    \n    # Fill missing values with 0\n    df.fillna(0, inplace=True)\n\n    # Splitting majority and minority classes\n    majority_class = df[df['class'] == 0]\n    minority_class = df[df['class'] == 1]\n    imbalance_ratio = len(majority_class) / len(minority_class)\n\n    # Create refined datasets\n    num_partitions = int(imbalance_ratio)\n    majority_partitions = np.array_split(majority_class, num_partitions)\n    refined_datasets = [pd.concat([minority_class, part]) for part in majority_partitions]\n\n    # Apply instance weighting\n    def assign_weights(dataset):\n        dataset['weights'] = dataset['class'].apply(lambda x: 1 if x == 1 else 1 / num_partitions)\n        return dataset\n\n    refined_datasets = [assign_weights(rd) for rd in refined_datasets]\n\n    # Generate subspace classifiers\n    def generate_subspace_classifiers(dataset, dataset_idx):\n        classifiers = []\n        features = dataset.drop(columns=['class', 'weights']).columns.tolist()\n        clf_count = 0  # Track classifier index\n\n        while features:\n            X = dataset[features]\n            y = dataset['class']\n            clf = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=4, random_state=42, max_features=None)\n            clf.fit(X, y)\n            selected_features = X.columns[clf.feature_importances_ > 0].tolist()\n            \n            if not selected_features:\n                break  # Stop if no important features are found\n            \n            # Assign unique classifier name\n            classifier_name = f'dt_{dataset_idx}_{clf_count}'\n            classifiers.append((classifier_name, DecisionTreeClassifier(\n                criterion='gini', splitter='best', max_depth=4, random_state=42, max_features=None\n            ).fit(X[selected_features], y)))\n            \n            # Remove selected features from further iterations\n            features = [f for f in features if f not in selected_features]\n            clf_count += 1\n\n        return classifiers\n\n    all_classifiers = []\n    for idx, rd in enumerate(refined_datasets):\n        all_classifiers.extend(generate_subspace_classifiers(rd, idx))\n\n    # Ensemble classifier\n    ensemble_clf = VotingClassifier(estimators=all_classifiers, voting='soft')\n    X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['class']), df['class'], test_size=0.2)\n    ensemble_clf.fit(X_train, y_train)\n    y_pred = ensemble_clf.predict(X_test)\n\n    # Compute performance metrics\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n    \n    # Store F1 Score for plotting\n    f1_scores.append(f1)\n\n    # Display results\n    print(f\"Missing Percentage: {missing_percentage}%\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")\n\n# Plot F1 score vs. Missing Percentage\nplt.figure(figsize=(8, 5))\nplt.plot(missing_percents, f1_scores, marker='o', linestyle='-', color='b')\nplt.xlabel(\"Percentage of Missing Values\")\nplt.ylabel(\"F1 Score\")\nplt.title(\"Impact of Missing Values on F1 Score\")\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T18:21:21.035356Z","iopub.execute_input":"2025-03-11T18:21:21.035751Z","iopub.status.idle":"2025-03-11T18:21:22.114773Z","shell.execute_reply.started":"2025-03-11T18:21:21.035717Z","shell.execute_reply":"2025-03-11T18:21:22.113431Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Load dataset\ndf_original = pd.read_csv('/kaggle/input/kidney-modified-dataset/Kidney_dataset_Modified.csv')  # Update path accordingly\n\n# Function to introduce missing values\ndef introduce_missing_values(data, missing_percentage):\n    data = data.copy()\n    total_values = data.size\n    missing_count = int((missing_percentage / 100) * total_values)\n    indices = np.random.choice(data.size, missing_count, replace=False)\n    flat_data = data.values.flatten()\n    flat_data[indices] = np.nan\n    return pd.DataFrame(flat_data.reshape(data.shape), columns=data.columns)\n\n# Store results for different percentages of missing values\nmissing_percents = [10, 20, 30, 40, 50]\nf1_scores = []\n\n# Iterate over different missing percentages\nfor missing_percentage in missing_percents:\n    print(f\"\\nEvaluating for {missing_percentage}% missing values...\")\n\n    # Introduce missing values\n    df = introduce_missing_values(df_original, missing_percentage)\n    \n    # Fill missing values with 0\n    df.fillna(0, inplace=True)\n\n    # Splitting majority and minority classes\n    majority_class = df[df['class'] == 0]\n    minority_class = df[df['class'] == 1]\n    imbalance_ratio = len(majority_class) / len(minority_class)\n\n    # Create refined datasets\n    num_partitions = int(imbalance_ratio)\n    majority_partitions = np.array_split(majority_class, num_partitions)\n    refined_datasets = [pd.concat([minority_class, part]) for part in majority_partitions]\n\n    print(f\"Total Refined Datasets Created: {len(refined_datasets)}\")\n\n    # Apply instance weighting\n    def assign_weights(dataset):\n        dataset['weights'] = dataset['class'].apply(lambda x: 1 if x == 1 else 1 / num_partitions)\n        return dataset\n\n    refined_datasets = [assign_weights(rd) for rd in refined_datasets]\n\n    # Generate subspace classifiers\n    def generate_subspace_classifiers(dataset, dataset_idx):\n        classifiers = []\n        features = dataset.drop(columns=['class', 'weights']).columns.tolist()\n        clf_count = 0  # Track classifier index\n\n        while features:\n            X = dataset[features]\n            y = dataset['class']\n            clf = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=4, random_state=42, max_features=None)\n            clf.fit(X, y)\n            selected_features = X.columns[clf.feature_importances_ > 0].tolist()\n            \n            if not selected_features:\n                break  # Stop if no important features are found\n            \n            # Assign unique classifier name\n            classifier_name = f'dt_{dataset_idx}_{clf_count}'\n            classifiers.append((classifier_name, DecisionTreeClassifier(\n                criterion='gini', splitter='best', max_depth=4, random_state=42, max_features=None\n            ).fit(X[selected_features], y)))\n            \n            # Remove selected features from further iterations\n            features = [f for f in features if f not in selected_features]\n            clf_count += 1\n\n        print(f\"Refined Dataset {dataset_idx}: {len(classifiers)} Subspace Classifiers Generated\")\n        return classifiers\n\n    all_classifiers = []\n    for idx, rd in enumerate(refined_datasets):\n        all_classifiers.extend(generate_subspace_classifiers(rd, idx))\n\n    # Ensemble classifier\n    ensemble_clf = VotingClassifier(estimators=all_classifiers, voting='soft')\n    X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['class']), df['class'], test_size=0.2)\n    ensemble_clf.fit(X_train, y_train)\n    y_pred = ensemble_clf.predict(X_test)\n\n    # Compute performance metrics\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n    \n    # Store F1 Score for plotting\n    f1_scores.append(f1)\n\n    # Display results\n    print(f\"Missing Percentage: {missing_percentage}%\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")\n\n# Plot F1 score vs. Missing Percentage\nplt.figure(figsize=(8, 5))\nplt.plot(missing_percents, f1_scores, marker='o', linestyle='-', color='b')\nplt.xlabel(\"Percentage of Missing Values\")\nplt.ylabel(\"F1 Score\")\nplt.title(\"Impact of Missing Values on F1 Score\")\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T18:26:40.144197Z","iopub.execute_input":"2025-03-11T18:26:40.145294Z","iopub.status.idle":"2025-03-11T18:26:40.833526Z","shell.execute_reply.started":"2025-03-11T18:26:40.14524Z","shell.execute_reply":"2025-03-11T18:26:40.832031Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Load dataset\ndf_original = pd.read_csv('/kaggle/input/kidney-modified-dataset/Kidney_dataset_Modified.csv')  # Update path accordingly\n\n# Function to introduce missing values\ndef introduce_missing_values(data, missing_percentage):\n    data = data.copy()\n    total_values = data.size\n    missing_count = int((missing_percentage / 100) * total_values)\n    indices = np.random.choice(data.size, missing_count, replace=False)\n    flat_data = data.values.flatten()\n    flat_data[indices] = np.nan\n    return pd.DataFrame(flat_data.reshape(data.shape), columns=data.columns)\n\n# Store results for different percentages of missing values\nmissing_percents = [10, 20, 30, 40, 50]\naccuracy_scores = []\nprecision_scores = []\nrecall_scores = []\nf1_scores = []\n\n# Iterate over different missing percentages\nfor missing_percentage in missing_percents:\n    print(f\"\\nEvaluating for {missing_percentage}% missing values...\")\n\n    # Introduce missing values\n    df = introduce_missing_values(df_original, missing_percentage)\n    \n    # Fill missing values with 0\n    df.fillna(0, inplace=True)\n\n    # Splitting majority and minority classes\n    majority_class = df[df['class'] == 0]\n    minority_class = df[df['class'] == 1]\n    imbalance_ratio = len(majority_class) / len(minority_class)\n\n    # Create refined datasets\n    num_partitions = max(2, int(imbalance_ratio))  # Ensure at least 2 partitions\n    majority_partitions = np.array_split(majority_class, num_partitions)\n    refined_datasets = [pd.concat([minority_class, part]) for part in majority_partitions]\n\n    print(f\"Total Refined Datasets Created: {len(refined_datasets)}\")\n\n    # Apply instance weighting\n    def assign_weights(dataset):\n        dataset['weights'] = dataset['class'].apply(lambda x: 1 if x == 1 else 1 / num_partitions)\n        return dataset\n\n    refined_datasets = [assign_weights(rd) for rd in refined_datasets]\n\n    # Generate subspace classifiers\n    def generate_subspace_classifiers(dataset, dataset_idx):\n        classifiers = []\n        features = dataset.drop(columns=['class', 'weights']).columns.tolist()\n        clf_count = 0  # Track classifier index\n\n        while features:\n            X = dataset[features]\n            y = dataset['class']\n            \n            if X.empty or y.empty:\n                print(f\"Skipping dataset {dataset_idx}: No data available.\")\n                break\n            \n            clf = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=4, random_state=42, max_features=None)\n            clf.fit(X, y)\n            selected_features = X.columns[clf.feature_importances_ > 0].tolist()\n            \n            if not selected_features:\n                break  # Stop if no important features are found\n            \n            # Assign unique classifier name\n            classifier_name = f'dt_{dataset_idx}_{clf_count}'\n            classifiers.append((classifier_name, DecisionTreeClassifier(\n                criterion='gini', splitter='best', max_depth=4, random_state=42, max_features=None\n            ).fit(X[selected_features], y)))\n            \n            # Remove selected features from further iterations\n            features = [f for f in features if f not in selected_features]\n            clf_count += 1\n\n        print(f\"Refined Dataset {dataset_idx}: {len(classifiers)} Subspace Classifiers Generated\")\n        return classifiers\n\n    all_classifiers = []\n    for idx, rd in enumerate(refined_datasets):\n        all_classifiers.extend(generate_subspace_classifiers(rd, idx))\n\n    if not all_classifiers:\n        print(f\"No classifiers generated for {missing_percentage}% missing values. Skipping evaluation.\")\n        continue\n\n    # Ensemble classifier\n    ensemble_clf = VotingClassifier(estimators=all_classifiers, voting='soft')\n    \n    try:\n        X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['class']), df['class'], test_size=0.2)\n        \n        if X_train.empty or y_train.empty:\n            print(f\"Skipping training for {missing_percentage}% missing values: No valid training data.\")\n            continue\n        \n        ensemble_clf.fit(X_train, y_train)\n        y_pred = ensemble_clf.predict(X_test)\n\n        # Compute performance metrics\n        accuracy = accuracy_score(y_test, y_pred)\n        precision = precision_score(y_test, y_pred)\n        recall = recall_score(y_test, y_pred)\n        f1 = f1_score(y_test, y_pred)\n\n        # Store results for plotting\n        accuracy_scores.append(accuracy)\n        precision_scores.append(precision)\n        recall_scores.append(recall)\n        f1_scores.append(f1)\n\n        # Display results\n        print(f\"Missing Percentage: {missing_percentage}%\")\n        print(f\"Accuracy: {accuracy:.4f}\")\n        print(f\"Precision: {precision:.4f}\")\n        print(f\"Recall: {recall:.4f}\")\n        print(f\"F1 Score: {f1:.4f}\")\n\n    except ValueError as e:\n        print(f\"Error encountered for {missing_percentage}% missing values: {e}\")\n        continue\n\n# Plot metrics vs. Missing Percentage\nplt.figure(figsize=(10, 6))\nplt.plot(missing_percents[:len(f1_scores)], accuracy_scores, marker='o', linestyle='-', label=\"Accuracy\", color='b')\nplt.plot(missing_percents[:len(f1_scores)], precision_scores, marker='s', linestyle='-', label=\"Precision\", color='g')\nplt.plot(missing_percents[:len(f1_scores)], recall_scores, marker='^', linestyle='-', label=\"Recall\", color='r')\nplt.plot(missing_percents[:len(f1_scores)], f1_scores, marker='d', linestyle='-', label=\"F1 Score\", color='purple')\n\nplt.xlabel(\"Percentage of Missing Values\")\nplt.ylabel(\"Performance Metrics\")\nplt.title(\"Impact of Missing Values on Model Performance\")\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T18:32:50.411118Z","iopub.execute_input":"2025-03-11T18:32:50.411529Z","iopub.status.idle":"2025-03-11T18:32:51.455533Z","shell.execute_reply.started":"2025-03-11T18:32:50.411496Z","shell.execute_reply":"2025-03-11T18:32:51.454357Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Hyper Parameter Tuning for better results ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Load dataset\ndf_original = pd.read_csv('/kaggle/input/kidney-modified-dataset/Kidney_dataset_Modified.csv')  # Update path accordingly\n\n# Function to introduce missing values\ndef introduce_missing_values(data, missing_percentage):\n    data = data.copy()\n    total_values = data.size\n    missing_count = int((missing_percentage / 100) * total_values)\n    indices = np.random.choice(data.size, missing_count, replace=False)\n    flat_data = data.values.flatten()\n    flat_data[indices] = np.nan\n    return pd.DataFrame(flat_data.reshape(data.shape), columns=data.columns)\n\n# Store results for different percentages of missing values\nmissing_percents = [10, 20, 30, 40, 50]\naccuracy_scores = []\nprecision_scores = []\nrecall_scores = []\nf1_scores = []\n\n# Iterate over different missing percentages\nfor missing_percentage in missing_percents:\n    print(f\"\\nEvaluating for {missing_percentage}% missing values...\")\n\n    # Introduce missing values\n    df = introduce_missing_values(df_original, missing_percentage)\n    \n    # Fill missing values with 0\n    df.fillna(0, inplace=True)\n\n    # Splitting majority and minority classes\n    majority_class = df[df['class'] == 0]\n    minority_class = df[df['class'] == 1]\n    imbalance_ratio = len(majority_class) / len(minority_class)\n\n    # Create refined datasets\n    num_partitions = max(2, int(imbalance_ratio))  # Ensure at least 2 partitions\n    majority_partitions = np.array_split(majority_class, num_partitions)\n    refined_datasets = [pd.concat([minority_class, part]) for part in majority_partitions]\n\n    print(f\"Total Refined Datasets Created: {len(refined_datasets)}\")\n\n    # Apply instance weighting\n    def assign_weights(dataset):\n        dataset['weights'] = dataset['class'].apply(lambda x: 1 if x == 1 else 1 / num_partitions)\n        return dataset\n\n    refined_datasets = [assign_weights(rd) for rd in refined_datasets]\n\n    # Generate subspace classifiers\n    def generate_subspace_classifiers(dataset, dataset_idx):\n        classifiers = []\n        features = dataset.drop(columns=['class', 'weights']).columns.tolist()\n        clf_count = 0  # Track classifier index\n\n        while features:\n            X = dataset[features]\n            y = dataset['class']\n            \n            if X.empty or y.empty:\n                print(f\"Skipping dataset {dataset_idx}: No data available.\")\n                break\n            \n            clf = DecisionTreeClassifier(\n                criterion='entropy',  # Changed from 'gini' to 'entropy' for better splits\n                splitter='best',\n                max_depth=10,  # Increased depth to improve learning\n                min_samples_split=5,  # Ensuring meaningful splits\n                min_samples_leaf=2,  # Avoiding overfitting\n                class_weight='balanced',  # Handling class imbalance\n                random_state=42\n            )\n            clf.fit(X, y)\n            selected_features = X.columns[clf.feature_importances_ > 0].tolist()\n            \n            if not selected_features:\n                break  # Stop if no important features are found\n            \n            # Assign unique classifier name\n            classifier_name = f'dt_{dataset_idx}_{clf_count}'\n            classifiers.append((classifier_name, DecisionTreeClassifier(\n                criterion='entropy',\n                splitter='best',\n                max_depth=10,\n                min_samples_split=5,\n                min_samples_leaf=2,\n                class_weight='balanced',\n                random_state=42\n            ).fit(X[selected_features], y)))\n            \n            # Remove selected features from further iterations\n            features = [f for f in features if f not in selected_features]\n            clf_count += 1\n\n        print(f\"Refined Dataset {dataset_idx}: {len(classifiers)} Subspace Classifiers Generated\")\n        return classifiers\n\n    all_classifiers = []\n    for idx, rd in enumerate(refined_datasets):\n        all_classifiers.extend(generate_subspace_classifiers(rd, idx))\n\n    if not all_classifiers:\n        print(f\"No classifiers generated for {missing_percentage}% missing values. Skipping evaluation.\")\n        continue\n\n    # Ensemble classifier\n    ensemble_clf = VotingClassifier(estimators=all_classifiers, voting='soft')\n    \n    try:\n        X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['class']), df['class'], test_size=0.2)\n        \n        if X_train.empty or y_train.empty:\n            print(f\"Skipping training for {missing_percentage}% missing values: No valid training data.\")\n            continue\n        \n        ensemble_clf.fit(X_train, y_train)\n        y_pred = ensemble_clf.predict(X_test)\n\n        # Compute performance metrics\n        accuracy = accuracy_score(y_test, y_pred)\n        precision = precision_score(y_test, y_pred)\n        recall = recall_score(y_test, y_pred)\n        f1 = f1_score(y_test, y_pred)\n\n        # Store results for plotting\n        accuracy_scores.append(accuracy)\n        precision_scores.append(precision)\n        recall_scores.append(recall)\n        f1_scores.append(f1)\n\n        # Display results\n        print(f\"Missing Percentage: {missing_percentage}%\")\n        print(f\"Accuracy: {accuracy:.4f}\")\n        print(f\"Precision: {precision:.4f}\")\n        print(f\"Recall: {recall:.4f}\")\n        print(f\"F1 Score: {f1:.4f}\")\n\n    except ValueError as e:\n        print(f\"Error encountered for {missing_percentage}% missing values: {e}\")\n        continue\n\n# Plot metrics vs. Missing Percentage\nplt.figure(figsize=(10, 6))\nplt.plot(missing_percents[:len(f1_scores)], accuracy_scores, marker='o', linestyle='-', label=\"Accuracy\", color='b')\nplt.plot(missing_percents[:len(f1_scores)], precision_scores, marker='s', linestyle='-', label=\"Precision\", color='g')\nplt.plot(missing_percents[:len(f1_scores)], recall_scores, marker='^', linestyle='-', label=\"Recall\", color='r')\nplt.plot(missing_percents[:len(f1_scores)], f1_scores, marker='d', linestyle='-', label=\"F1 Score\", color='purple')\n\nplt.xlabel(\"Percentage of Missing Values\")\nplt.ylabel(\"Performance Metrics\")\nplt.title(\"Impact of Missing Values on Model Performance\")\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T18:44:28.397615Z","iopub.execute_input":"2025-03-11T18:44:28.39802Z","iopub.status.idle":"2025-03-11T18:44:29.269087Z","shell.execute_reply.started":"2025-03-11T18:44:28.397989Z","shell.execute_reply":"2025-03-11T18:44:29.267868Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Instance weigting considered","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Load dataset\ndf_original = pd.read_csv('/kaggle/input/kidney-modified-dataset/Kidney_dataset_Modified.csv')  # Update path accordingly\n\n# Function to introduce missing values\ndef introduce_missing_values(data, missing_percentage):\n    data = data.copy()\n    total_values = data.size\n    missing_count = int((missing_percentage / 100) * total_values)\n    indices = np.random.choice(data.size, missing_count, replace=False)\n    flat_data = data.values.flatten()\n    flat_data[indices] = np.nan\n    return pd.DataFrame(flat_data.reshape(data.shape), columns=data.columns)\n\n# Store results for different percentages of missing values\nmissing_percents = [10, 20, 30, 40, 50]\naccuracy_scores = []\nprecision_scores = []\nrecall_scores = []\nf1_scores = []\n\n# Iterate over different missing percentages\nfor missing_percentage in missing_percents:\n    print(f\"\\nEvaluating for {missing_percentage}% missing values...\")\n\n    # Introduce missing values\n    df = introduce_missing_values(df_original, missing_percentage)\n    \n    # Fill missing values with 0\n    df.fillna(0, inplace=True)\n\n    # Splitting majority and minority classes\n    majority_class = df[df['class'] == 0]\n    minority_class = df[df['class'] == 1]\n    Nm = len(minority_class)\n    NM = len(majority_class)\n    \n    # Create refined datasets\n    num_partitions = max(2, int(NM / Nm))  # Ensure at least 2 partitions\n    majority_partitions = np.array_split(majority_class, num_partitions)\n    refined_datasets = [pd.concat([minority_class, part]) for part in majority_partitions]\n\n    print(f\"Total Refined Datasets Created: {len(refined_datasets)}\")\n\n    # Apply instance weighting\n    def assign_weights(dataset):\n        dataset['weights'] = dataset['class'].apply(lambda x: 1/Nm if x == 1 else 1/NM)\n        return dataset\n\n    refined_datasets = [assign_weights(rd) for rd in refined_datasets]\n\n    # Generate subspace classifiers\n    def generate_subspace_classifiers(dataset, dataset_idx):\n        classifiers = []\n        features = dataset.drop(columns=['class', 'weights']).columns.tolist()\n        clf_count = 0  # Track classifier index\n\n        while features:\n            X = dataset[features]\n            y = dataset['class']\n            \n            if X.empty or y.empty:\n                print(f\"Skipping dataset {dataset_idx}: No data available.\")\n                break\n            \n            clf = DecisionTreeClassifier(criterion='entropy', splitter='best', max_depth=10, min_samples_split=5, \n                                         min_samples_leaf=2, random_state=42, max_features=None)\n            clf.fit(X, y, sample_weight=dataset['weights'])\n            selected_features = X.columns[clf.feature_importances_ > 0].tolist()\n            \n            if not selected_features:\n                break  # Stop if no important features are found\n            \n            # Assign unique classifier name\n            classifier_name = f'dt_{dataset_idx}_{clf_count}'\n            classifiers.append((classifier_name, DecisionTreeClassifier(\n                criterion='entropy', splitter='best', max_depth=10, min_samples_split=5, \n                min_samples_leaf=2, random_state=42, max_features=None\n            ).fit(X[selected_features], y, sample_weight=dataset['weights'])))\n            \n            # Remove selected features from further iterations\n            features = [f for f in features if f not in selected_features]\n            clf_count += 1\n\n        print(f\"Refined Dataset {dataset_idx}: {len(classifiers)} Subspace Classifiers Generated\")\n        return classifiers\n\n    all_classifiers = []\n    for idx, rd in enumerate(refined_datasets):\n        all_classifiers.extend(generate_subspace_classifiers(rd, idx))\n\n    if not all_classifiers:\n        print(f\"No classifiers generated for {missing_percentage}% missing values. Skipping evaluation.\")\n        continue\n\n    # Ensemble classifier\n    ensemble_clf = VotingClassifier(estimators=all_classifiers, voting='soft')\n    \n    try:\n        X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['class']), df['class'], test_size=0.2)\n        \n        if X_train.empty or y_train.empty:\n            print(f\"Skipping training for {missing_percentage}% missing values: No valid training data.\")\n            continue\n        \n        ensemble_clf.fit(X_train, y_train)\n        y_pred = ensemble_clf.predict(X_test)\n\n        # Compute performance metrics\n        accuracy = accuracy_score(y_test, y_pred)\n        precision = precision_score(y_test, y_pred)\n        recall = recall_score(y_test, y_pred)\n        f1 = f1_score(y_test, y_pred)\n\n        # Store results for plotting\n        accuracy_scores.append(accuracy)\n        precision_scores.append(precision)\n        recall_scores.append(recall)\n        f1_scores.append(f1)\n\n        # Display results\n        print(f\"Missing Percentage: {missing_percentage}%\")\n        print(f\"Accuracy: {accuracy:.4f}\")\n        print(f\"Precision: {precision:.4f}\")\n        print(f\"Recall: {recall:.4f}\")\n        print(f\"F1 Score: {f1:.4f}\")\n\n    except ValueError as e:\n        print(f\"Error encountered for {missing_percentage}% missing values: {e}\")\n        continue\n\n# Plot metrics vs. Missing Percentage\nplt.figure(figsize=(10, 6))\nplt.plot(missing_percents[:len(f1_scores)], accuracy_scores, marker='o', linestyle='-', label=\"Accuracy\", color='b')\nplt.plot(missing_percents[:len(f1_scores)], precision_scores, marker='s', linestyle='-', label=\"Precision\", color='g')\nplt.plot(missing_percents[:len(f1_scores)], recall_scores, marker='^', linestyle='-', label=\"Recall\", color='r')\nplt.plot(missing_percents[:len(f1_scores)], f1_scores, marker='d', linestyle='-', label=\"F1 Score\", color='purple')\n\nplt.xlabel(\"Percentage of Missing Values\")\nplt.ylabel(\"Performance Metrics\")\nplt.title(\"Impact of Missing Values on Model Performance\")\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T18:49:29.624961Z","iopub.execute_input":"2025-03-11T18:49:29.625352Z","iopub.status.idle":"2025-03-11T18:49:30.466267Z","shell.execute_reply.started":"2025-03-11T18:49:29.62532Z","shell.execute_reply":"2025-03-11T18:49:30.465153Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Displaying Instance weighting and hyper parameter tuning ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Load dataset\ndf_original = pd.read_csv('/kaggle/input/kidney-modified-dataset/Kidney_dataset_Modified.csv')  # Update path accordingly\n\n# Function to introduce missing values\ndef introduce_missing_values(data, missing_percentage):\n    data = data.copy()\n    total_values = data.size\n    missing_count = int((missing_percentage / 100) * total_values)\n    indices = np.random.choice(data.size, missing_count, replace=False)\n    flat_data = data.values.flatten()\n    flat_data[indices] = np.nan\n    return pd.DataFrame(flat_data.reshape(data.shape), columns=data.columns)\n\n# Store results for different percentages of missing values\nmissing_percents = [10, 20, 30, 40, 50]\naccuracy_scores = []\nprecision_scores = []\nrecall_scores = []\nf1_scores = []\n\n# Iterate over different missing percentages\nfor missing_percentage in missing_percents:\n    print(f\"\\nEvaluating for {missing_percentage}% missing values...\")\n\n    # Introduce missing values\n    df = introduce_missing_values(df_original, missing_percentage)\n    \n    # Fill missing values with 0\n    df.fillna(0, inplace=True)\n\n    # Splitting majority and minority classes\n    majority_class = df[df['class'] == 0]\n    minority_class = df[df['class'] == 1]\n    Nm = len(minority_class)\n    NM = len(majority_class)\n\n    # Compute instance weights\n    wm = 1 / Nm if Nm > 0 else 0\n    wM = 1 / NM if NM > 0 else 0\n    print(f\"Instance Weights - Minority: {wm:.4f}, Majority: {wM:.4f}\")\n\n    # Create refined datasets\n    num_partitions = max(2, int(NM / Nm)) if Nm > 0 else 1\n    majority_partitions = np.array_split(majority_class, num_partitions)\n    refined_datasets = [pd.concat([minority_class, part]) for part in majority_partitions]\n    print(f\"Total Refined Datasets Created: {len(refined_datasets)}\")\n\n    # Apply instance weighting\n    def assign_weights(dataset):\n        dataset['weights'] = dataset['class'].apply(lambda x: wm if x == 1 else wM)\n        return dataset\n\n    refined_datasets = [assign_weights(rd) for rd in refined_datasets]\n\n    # Generate subspace classifiers\n    def generate_subspace_classifiers(dataset, dataset_idx):\n        classifiers = []\n        features = dataset.drop(columns=['class', 'weights']).columns.tolist()\n        clf_count = 0\n\n        while features:\n            X = dataset[features]\n            y = dataset['class']\n            \n            if X.empty or y.empty:\n                break\n            \n            clf = DecisionTreeClassifier(criterion='entropy', splitter='best', max_depth=6, min_samples_split=4, \n                                         min_samples_leaf=2, class_weight='balanced', random_state=42)\n            clf.fit(X, y, sample_weight=dataset['weights'])\n            selected_features = X.columns[clf.feature_importances_ > 0].tolist()\n            \n            if not selected_features:\n                break\n            \n            classifier_name = f'dt_{dataset_idx}_{clf_count}'\n            classifiers.append((classifier_name, DecisionTreeClassifier(\n                criterion='entropy', splitter='best', max_depth=6, min_samples_split=4,\n                min_samples_leaf=2, class_weight='balanced', random_state=42\n            ).fit(X[selected_features], y, sample_weight=dataset['weights'])))\n            \n            features = [f for f in features if f not in selected_features]\n            clf_count += 1\n\n        return classifiers\n\n    all_classifiers = []\n    for idx, rd in enumerate(refined_datasets):\n        all_classifiers.extend(generate_subspace_classifiers(rd, idx))\n\n    if not all_classifiers:\n        continue\n\n    # Ensemble classifier\n    ensemble_clf = VotingClassifier(estimators=all_classifiers, voting='soft')\n    \n    try:\n        X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['class']), df['class'], test_size=0.2)\n        \n        if X_train.empty or y_train.empty:\n            continue\n        \n        ensemble_clf.fit(X_train, y_train)\n        y_pred = ensemble_clf.predict(X_test)\n\n        # Compute performance metrics\n        accuracy = accuracy_score(y_test, y_pred)\n        precision = precision_score(y_test, y_pred)\n        recall = recall_score(y_test, y_pred)\n        f1 = f1_score(y_test, y_pred)\n\n        # Store results\n        accuracy_scores.append(accuracy)\n        precision_scores.append(precision)\n        recall_scores.append(recall)\n        f1_scores.append(f1)\n\n        print(f\"Missing Percentage: {missing_percentage}%\")\n        print(f\"Accuracy: {accuracy:.4f}\")\n        print(f\"Precision: {precision:.4f}\")\n        print(f\"Recall: {recall:.4f}\")\n        print(f\"F1 Score: {f1:.4f}\")\n    \n    except ValueError as e:\n        print(f\"Error encountered: {e}\")\n        continue\n\n# Plot metrics vs. Missing Percentage\nplt.figure(figsize=(10, 6))\nplt.plot(missing_percents[:len(f1_scores)], accuracy_scores, marker='o', linestyle='-', label=\"Accuracy\", color='b')\nplt.plot(missing_percents[:len(f1_scores)], precision_scores, marker='s', linestyle='-', label=\"Precision\", color='g')\nplt.plot(missing_percents[:len(f1_scores)], recall_scores, marker='^', linestyle='-', label=\"Recall\", color='r')\nplt.plot(missing_percents[:len(f1_scores)], f1_scores, marker='d', linestyle='-', label=\"F1 Score\", color='purple')\n\nplt.xlabel(\"Percentage of Missing Values\")\nplt.ylabel(\"Performance Metrics\")\nplt.title(\"Impact of Missing Values on Model Performance\")\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T18:53:49.003632Z","iopub.execute_input":"2025-03-11T18:53:49.004061Z","iopub.status.idle":"2025-03-11T18:53:50.139609Z","shell.execute_reply.started":"2025-03-11T18:53:49.004027Z","shell.execute_reply":"2025-03-11T18:53:50.137767Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Proper Division of dataset in to refined datasets and instance weights assigned ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Load dataset\ndf_original = pd.read_csv('/kaggle/input/kidney-modified-dataset/Kidney_dataset_Modified.csv')  # Update path accordingly\n\n# Function to introduce missing values\ndef introduce_missing_values(data, missing_percentage):\n    data = data.copy()\n    total_values = data.size\n    missing_count = int((missing_percentage / 100) * total_values)\n    indices = np.random.choice(data.size, missing_count, replace=False)\n    flat_data = data.values.flatten()\n    flat_data[indices] = np.nan\n    return pd.DataFrame(flat_data.reshape(data.shape), columns=data.columns)\n\n# Store results for different percentages of missing values\nmissing_percents = [10, 20, 30, 40, 50]\naccuracy_scores = []\nprecision_scores = []\nrecall_scores = []\nf1_scores = []\n\n# Iterate over different missing percentages\nfor missing_percentage in missing_percents:\n    print(f\"\\nEvaluating for {missing_percentage}% missing values...\")\n\n    # Introduce missing values\n    df = introduce_missing_values(df_original, missing_percentage)\n    \n    # Fill missing values with 0\n    df.fillna(0, inplace=True)\n\n    # Splitting majority and minority classes\n    majority_class = df[df['class'] == 0]\n    minority_class = df[df['class'] == 1]\n    \n    # Create 2 refined datasets\n    majority_partitions = np.array_split(majority_class, 2)\n    refined_datasets = [pd.concat([minority_class, part]) for part in majority_partitions]\n    \n    print(f\"Total Refined Datasets Created: {len(refined_datasets)}\")\n\n    # Apply fixed instance weighting\n    def assign_weights(dataset):\n        dataset['weights'] = dataset['class'].apply(lambda x: 1 if x == 1 else 0.5)\n        return dataset\n\n    refined_datasets = [assign_weights(rd) for rd in refined_datasets]\n    \n    # Display the assigned weights\n    print(f\"Assigned Weights: Minority = 1, Majority = 0.5\")\n    \n    # Generate subspace classifiers\n    def generate_subspace_classifiers(dataset, dataset_idx):\n        classifiers = []\n        features = dataset.drop(columns=['class', 'weights']).columns.tolist()\n        clf_count = 0  # Track classifier index\n\n        while features:\n            X = dataset[features]\n            y = dataset['class']\n            \n            if X.empty or y.empty:\n                print(f\"Skipping dataset {dataset_idx}: No data available.\")\n                break\n            \n            clf = DecisionTreeClassifier(\n                criterion='entropy',\n                splitter='best',\n                max_depth=6,\n                min_samples_split=4,\n                min_samples_leaf=2,\n                random_state=42,\n                class_weight='balanced'\n            )\n            clf.fit(X, y)\n            selected_features = X.columns[clf.feature_importances_ > 0].tolist()\n            \n            if not selected_features:\n                break  # Stop if no important features are found\n            \n            classifier_name = f'dt_{dataset_idx}_{clf_count}'\n            classifiers.append((classifier_name, DecisionTreeClassifier(\n                criterion='entropy',\n                splitter='best',\n                max_depth=6,\n                min_samples_split=4,\n                min_samples_leaf=2,\n                random_state=42,\n                class_weight='balanced'\n            ).fit(X[selected_features], y)))\n            \n            features = [f for f in features if f not in selected_features]\n            clf_count += 1\n\n        print(f\"Refined Dataset {dataset_idx}: {len(classifiers)} Subspace Classifiers Generated\")\n        return classifiers\n\n    all_classifiers = []\n    for idx, rd in enumerate(refined_datasets):\n        all_classifiers.extend(generate_subspace_classifiers(rd, idx))\n\n    if not all_classifiers:\n        print(f\"No classifiers generated for {missing_percentage}% missing values. Skipping evaluation.\")\n        continue\n\n    # Ensemble classifier\n    ensemble_clf = VotingClassifier(estimators=all_classifiers, voting='soft')\n    \n    try:\n        X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['class']), df['class'], test_size=0.2)\n        \n        if X_train.empty or y_train.empty:\n            print(f\"Skipping training for {missing_percentage}% missing values: No valid training data.\")\n            continue\n        \n        ensemble_clf.fit(X_train, y_train)\n        y_pred = ensemble_clf.predict(X_test)\n\n        # Compute performance metrics\n        accuracy = accuracy_score(y_test, y_pred)\n        precision = precision_score(y_test, y_pred)\n        recall = recall_score(y_test, y_pred)\n        f1 = f1_score(y_test, y_pred)\n\n        # Store results for plotting\n        accuracy_scores.append(accuracy)\n        precision_scores.append(precision)\n        recall_scores.append(recall)\n        f1_scores.append(f1)\n\n        # Display results\n        print(f\"Missing Percentage: {missing_percentage}%\")\n        print(f\"Accuracy: {accuracy:.4f}\")\n        print(f\"Precision: {precision:.4f}\")\n        print(f\"Recall: {recall:.4f}\")\n        print(f\"F1 Score: {f1:.4f}\")\n\n    except ValueError as e:\n        print(f\"Error encountered for {missing_percentage}% missing values: {e}\")\n        continue\n\n# Plot metrics vs. Missing Percentage\nplt.figure(figsize=(10, 6))\nplt.plot(missing_percents[:len(f1_scores)], accuracy_scores, marker='o', linestyle='-', label=\"Accuracy\", color='b')\nplt.plot(missing_percents[:len(f1_scores)], precision_scores, marker='s', linestyle='-', label=\"Precision\", color='g')\nplt.plot(missing_percents[:len(f1_scores)], recall_scores, marker='^', linestyle='-', label=\"Recall\", color='r')\nplt.plot(missing_percents[:len(f1_scores)], f1_scores, marker='d', linestyle='-', label=\"F1 Score\", color='purple')\n\nplt.xlabel(\"Percentage of Missing Values\")\nplt.ylabel(\"Performance Metrics\")\nplt.title(\"Impact of Missing Values on Model Performance\")\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T18:57:44.335175Z","iopub.execute_input":"2025-03-11T18:57:44.335582Z","iopub.status.idle":"2025-03-11T18:57:45.277748Z","shell.execute_reply.started":"2025-03-11T18:57:44.335548Z","shell.execute_reply":"2025-03-11T18:57:45.276539Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Manual ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n\n# Libraries 📖","metadata":{},"attachments":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nfrom sklearn.impute import SimpleImputer\nimport pandas as pd\nfrom numpy import isnan\nfrom sklearn.preprocessing import LabelEncoder\nfrom numpy import nan\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport plotly.express as px\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# For Model Evaluation\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.metrics import roc_curve, auc \nfrom matplotlib import pyplot\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:21:52.938516Z","iopub.execute_input":"2024-02-01T08:21:52.939027Z","iopub.status.idle":"2024-02-01T08:21:52.972959Z","shell.execute_reply.started":"2024-02-01T08:21:52.938993Z","shell.execute_reply":"2024-02-01T08:21:52.972012Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load data 📁","metadata":{}},{"cell_type":"code","source":"df_data=pd.read_csv(\"../input/ckdisease/kidney_disease.csv\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-01T08:21:57.233583Z","iopub.execute_input":"2024-02-01T08:21:57.23406Z","iopub.status.idle":"2024-02-01T08:21:57.249684Z","shell.execute_reply.started":"2024-02-01T08:21:57.234021Z","shell.execute_reply":"2024-02-01T08:21:57.248598Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_data","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:21:59.783096Z","iopub.execute_input":"2024-02-01T08:21:59.783564Z","iopub.status.idle":"2024-02-01T08:21:59.829866Z","shell.execute_reply.started":"2024-02-01T08:21:59.783531Z","shell.execute_reply":"2024-02-01T08:21:59.828581Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data analysis 📊","metadata":{}},{"cell_type":"code","source":"df_data.info()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:22:03.158284Z","iopub.execute_input":"2024-02-01T08:22:03.158751Z","iopub.status.idle":"2024-02-01T08:22:03.180218Z","shell.execute_reply.started":"2024-02-01T08:22:03.158717Z","shell.execute_reply":"2024-02-01T08:22:03.178472Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_data.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:22:06.230523Z","iopub.execute_input":"2024-02-01T08:22:06.230953Z","iopub.status.idle":"2024-02-01T08:22:06.265874Z","shell.execute_reply.started":"2024-02-01T08:22:06.23092Z","shell.execute_reply":"2024-02-01T08:22:06.263755Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"border-radius: 10px; border: #0ea5e9 solid; padding: 15px; background-color: #ffffff00; font-size: 100%; text-align: left;\">📉 Observation\n      <li><b>Observation One:</b>All Column Names</b> are not user-friendly.</li>\n      <li><b>Observation Two:</b>Following columns values in numeric but reflect as text column\n        <ul>\n          <li>pcv (packed_cell_volume)</li>\n          <li>wc (white_blood_cell_count)</li>\n          <li>rc (red_blood_cell_count)</li>\n        </ul>\n      </li>\n</div>","metadata":{}},{"cell_type":"code","source":"missing = df_data.isnull().sum()\nmissing[missing > 0].sort_values(ascending=False).head(20)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:22:10.208961Z","iopub.execute_input":"2024-02-01T08:22:10.209928Z","iopub.status.idle":"2024-02-01T08:22:10.22411Z","shell.execute_reply.started":"2024-02-01T08:22:10.209883Z","shell.execute_reply":"2024-02-01T08:22:10.222448Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# dropping 'id' column\ndf_data.drop('id', axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:22:15.427664Z","iopub.execute_input":"2024-02-01T08:22:15.428073Z","iopub.status.idle":"2024-02-01T08:22:15.435704Z","shell.execute_reply.started":"2024-02-01T08:22:15.428044Z","shell.execute_reply":"2024-02-01T08:22:15.434414Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"border-radius: 10px; border: #0ea5e9 solid; padding: 15px; background-color: #ffffff00; font-size: 100%; text-align: left;\"><b>📉 Observation :</b>\n    <li><b>Observation Three:</b> Certain columns contain <b>missing data</B> that necessitates our attention and management.</li>\n</div>","metadata":{}},{"cell_type":"code","source":"print(f\"dm :- {df_data['dm'].unique()}\")\nprint(f\"cad :- {df_data['cad'].unique()}\")\nprint(f\"classification :- {df_data['classification'].unique()}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:22:18.865215Z","iopub.execute_input":"2024-02-01T08:22:18.865817Z","iopub.status.idle":"2024-02-01T08:22:18.875564Z","shell.execute_reply.started":"2024-02-01T08:22:18.865763Z","shell.execute_reply":"2024-02-01T08:22:18.873748Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"border-radius: 10px; border: #0ea5e9 solid; padding: 15px; background-color: #ffffff00; font-size: 100%; text-align: left;\"><b>📉 Observation :</b>\n    <li><b>Observation Four:</b> There are typo errors in dm (diabetes_mellitus), cad (coronary_artery_disease), and classification (class) columns</li>\n    <li><b>Observation Five:</b> Need to change all column with Text value to Numeric</li>\n</div>","metadata":{}},{"cell_type":"markdown","source":"# Preprocessing ⚙️ ","metadata":{}},{"cell_type":"markdown","source":"<li><b>Resolving Observation One:</b> Allocate more user-friendly names to the columns</li>","metadata":{}},{"cell_type":"code","source":"# Notice the unfriendly column names\ndf_data.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:22:22.431691Z","iopub.execute_input":"2024-02-01T08:22:22.432564Z","iopub.status.idle":"2024-02-01T08:22:22.468106Z","shell.execute_reply.started":"2024-02-01T08:22:22.432508Z","shell.execute_reply":"2024-02-01T08:22:22.466287Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_data.columns = ['age', 'blood_pressure', 'specific_gravity', 'albumin', 'sugar', 'red_blood_cells', 'pus_cell',\n              'pus_cell_clumps', 'bacteria', 'blood_glucose_random', 'blood_urea', 'serum_creatinine', 'sodium',\n              'potassium', 'haemoglobin', 'packed_cell_volume', 'white_blood_cell_count', 'red_blood_cell_count',\n              'hypertension', 'diabetes_mellitus', 'coronary_artery_disease', 'appetite', 'peda_edema',\n              'anemia', 'class']","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:22:25.689484Z","iopub.execute_input":"2024-02-01T08:22:25.690147Z","iopub.status.idle":"2024-02-01T08:22:25.697926Z","shell.execute_reply.started":"2024-02-01T08:22:25.690112Z","shell.execute_reply":"2024-02-01T08:22:25.696761Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Friendly column names allocated\ndf_data.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:22:28.618528Z","iopub.execute_input":"2024-02-01T08:22:28.618962Z","iopub.status.idle":"2024-02-01T08:22:28.649868Z","shell.execute_reply.started":"2024-02-01T08:22:28.618929Z","shell.execute_reply":"2024-02-01T08:22:28.648645Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"border-radius: 10px; border: #ff001c solid; padding: 15px; margin-top: 15px; background-color: #ffffff00; font-size: \n            100%; text-align: left;\">\n    <b> 🚩 Column Names renamed successfully</b>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<li><b>Resolving Observation Two:</b> Converting text columns (packed_cell_volume, white_blood_cell_count and red_blood_cell_count) to numeric format</li>","metadata":{}},{"cell_type":"code","source":"# Notice these columns are of datatype Object\ntext_columns = ['packed_cell_volume', 'white_blood_cell_count', 'red_blood_cell_count']\n\nfor column in text_columns:\n    print(f\"{column} -: {df_data[column].dtype}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:22:32.587277Z","iopub.execute_input":"2024-02-01T08:22:32.588319Z","iopub.status.idle":"2024-02-01T08:22:32.594831Z","shell.execute_reply.started":"2024-02-01T08:22:32.588262Z","shell.execute_reply":"2024-02-01T08:22:32.593515Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert text column to numeric column\ndef convert_text_to_numeric_col (dataframe, feature):\n    dataframe[feature] = pd.to_numeric(df_data[feature], errors='coerce')\n\nfor column in text_columns:\n    convert_text_to_numeric_col(df_data, column)\n    print(f\"text_columns: {df_data[column].dtype}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:22:35.426322Z","iopub.execute_input":"2024-02-01T08:22:35.426716Z","iopub.status.idle":"2024-02-01T08:22:35.437102Z","shell.execute_reply.started":"2024-02-01T08:22:35.426687Z","shell.execute_reply":"2024-02-01T08:22:35.435985Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"border-radius: 10px; border: #ff001c solid; padding: 15px; margin-top: 15px; background-color: #ffffff00; font-size: \n            100%; text-align: left;\">\n    <b> 🚩 Column Names (packed_cell_volume, white_blood_cell_count and red_blood_cell_count) converted to numeric successfully</b>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<li><b>Resolving Observation Three:</b> Resolving missing data</li>","metadata":{}},{"cell_type":"code","source":"# Replacing missing values in all numeric columns with mean\n'''def mean_value_imputation(dataframe, feature):\n    mean_value=dataframe[feature].mean()\n    dataframe[feature].fillna(value=mean_value, inplace=True)\n\n# Replacing missing values in all categorical columns with highest frequency data\ndef impute_mode(dataframe, feature):\n    mode = dataframe[feature].mode()[0]\n    dataframe[feature] = dataframe[feature].fillna(mode)  '''","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:22:40.638764Z","iopub.execute_input":"2024-02-01T08:22:40.639712Z","iopub.status.idle":"2024-02-01T08:22:40.648325Z","shell.execute_reply.started":"2024-02-01T08:22:40.639674Z","shell.execute_reply":"2024-02-01T08:22:40.647149Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Obtaining columns names of all numerical features\n'''num_columns = [col for col in df_data.columns if df_data[col].dtype != 'object']\n\n# Assigning random number to all missing data in numeric columns\nfor column_name in num_columns:\n    mean_value_imputation(df_data,column_name)'''","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:22:43.87719Z","iopub.execute_input":"2024-02-01T08:22:43.878483Z","iopub.status.idle":"2024-02-01T08:22:43.886923Z","shell.execute_reply.started":"2024-02-01T08:22:43.87843Z","shell.execute_reply":"2024-02-01T08:22:43.885722Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Obtaining columns names of all categorized features\n'''cat_columns = [col for col in df_data.columns if df_data[col].dtype == 'object']\nimpute_mode(df_data,\"blood_pressure\")\n\n# Assigning highest frequency to all missing data in categorical columns\nfor column_name in cat_columns:\n    impute_mode(df_data,column_name)'''","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:22:46.568645Z","iopub.execute_input":"2024-02-01T08:22:46.570064Z","iopub.status.idle":"2024-02-01T08:22:46.578613Z","shell.execute_reply.started":"2024-02-01T08:22:46.569981Z","shell.execute_reply":"2024-02-01T08:22:46.577052Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing = df_data.isnull().sum()\nmissing[missing > 0].sort_values(ascending=False).head(20)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:22:51.912109Z","iopub.execute_input":"2024-02-01T08:22:51.91259Z","iopub.status.idle":"2024-02-01T08:22:51.930131Z","shell.execute_reply.started":"2024-02-01T08:22:51.912553Z","shell.execute_reply":"2024-02-01T08:22:51.928442Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"border-radius: 10px; border: #ff001c solid; padding: 15px; margin-top: 15px; background-color: #ffffff00; font-size: \n            100%; text-align: left;\">\n    <b> 🚩 All missing values have been filled up</b>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<li><b>Resolving Observation Four:</b> Typo Errors in dm (diabetes_mellitus), cad (coronary_artery_disease), and classification (class) columns</li>","metadata":{}},{"cell_type":"code","source":"print(f\"diabetes_mellitus :- {df_data['diabetes_mellitus'].unique()}\")\nprint(f\"coronary_artery_disease :- {df_data['coronary_artery_disease'].unique()}\")\nprint(f\"class :- {df_data['class'].unique()}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:23:34.485126Z","iopub.execute_input":"2024-02-01T08:23:34.485722Z","iopub.status.idle":"2024-02-01T08:23:34.496289Z","shell.execute_reply.started":"2024-02-01T08:23:34.485684Z","shell.execute_reply":"2024-02-01T08:23:34.494697Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_data['diabetes_mellitus'] = df_data['diabetes_mellitus'].replace(to_replace = {' yes':'yes', '\\tno':'no', '\\tyes':'yes'})\ndf_data['coronary_artery_disease'] = df_data['coronary_artery_disease'].replace(to_replace = '\\tno', value='no')\ndf_data['class'] = df_data['class'].replace(to_replace = {'ckd\\t': 'ckd', 'notckd': 'not ckd'})","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:23:38.546595Z","iopub.execute_input":"2024-02-01T08:23:38.547053Z","iopub.status.idle":"2024-02-01T08:23:38.558946Z","shell.execute_reply.started":"2024-02-01T08:23:38.547022Z","shell.execute_reply":"2024-02-01T08:23:38.557305Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"diabetes_mellitus'] :- {df_data['diabetes_mellitus'].unique()}\")\nprint(f\"coronary_artery_disease :- {df_data['coronary_artery_disease'].unique()}\")\nprint(f\"class :- {df_data['class'].unique()}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:23:42.041837Z","iopub.execute_input":"2024-02-01T08:23:42.042305Z","iopub.status.idle":"2024-02-01T08:23:42.050955Z","shell.execute_reply.started":"2024-02-01T08:23:42.04227Z","shell.execute_reply":"2024-02-01T08:23:42.049292Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"border-radius: 10px; border: #ff001c solid; padding: 15px; margin-top: 15px; background-color: #ffffff00; font-size: \n            100%; text-align: left;\">\n    <b> 🚩 All typo errors for the three columns rectified</b>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<li><b>Resolving Observation Five:</b> Feature Encoding - Need to change all column with Text value to Numeric</li>","metadata":{}},{"cell_type":"code","source":"df_data['class'] = df_data['class'].map({'ckd': 1, 'not ckd': 0})\ndf_data['red_blood_cells'] = df_data['red_blood_cells'].map({'normal': 1, 'abnormal': 0})\ndf_data['pus_cell'] = df_data['pus_cell'].map({'normal': 1, 'abnormal': 0})\ndf_data['pus_cell_clumps'] = df_data['pus_cell_clumps'].map({'present': 1, 'notpresent': 0})\ndf_data['bacteria'] = df_data['bacteria'].map({'present': 1, 'notpresent': 0})\ndf_data['hypertension'] = df_data['hypertension'].map({'yes': 1, 'no': 0})\ndf_data['diabetes_mellitus'] = df_data['diabetes_mellitus'].map({'yes': 1, 'no': 0})\ndf_data['coronary_artery_disease'] = df_data['coronary_artery_disease'].map({'yes': 1, 'no': 0}) \ndf_data['appetite'] = df_data['appetite'].map({'good': 1, 'poor': 0})\ndf_data['peda_edema'] = df_data['peda_edema'].map({'yes': 1, 'no': 0})\ndf_data['anemia'] = df_data['anemia'].map({'yes': 1, 'no': 0})","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:23:48.108209Z","iopub.execute_input":"2024-02-01T08:23:48.108744Z","iopub.status.idle":"2024-02-01T08:23:48.137017Z","shell.execute_reply.started":"2024-02-01T08:23:48.108704Z","shell.execute_reply":"2024-02-01T08:23:48.135475Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for column in text_columns:\n    convert_text_to_numeric_col(df_data, column)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:24:08.603818Z","iopub.execute_input":"2024-02-01T08:24:08.604387Z","iopub.status.idle":"2024-02-01T08:24:08.613325Z","shell.execute_reply.started":"2024-02-01T08:24:08.604351Z","shell.execute_reply":"2024-02-01T08:24:08.611206Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:24:11.899778Z","iopub.execute_input":"2024-02-01T08:24:11.900304Z","iopub.status.idle":"2024-02-01T08:24:11.94669Z","shell.execute_reply.started":"2024-02-01T08:24:11.900267Z","shell.execute_reply":"2024-02-01T08:24:11.945405Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_data.to_csv('newmodifieddataset.csv')","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:24:32.397752Z","iopub.execute_input":"2024-02-01T08:24:32.398249Z","iopub.status.idle":"2024-02-01T08:24:32.419704Z","shell.execute_reply.started":"2024-02-01T08:24:32.398203Z","shell.execute_reply":"2024-02-01T08:24:32.417704Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_data","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:08:41.963573Z","iopub.execute_input":"2024-02-01T08:08:41.964035Z","iopub.status.idle":"2024-02-01T08:08:42.033508Z","shell.execute_reply.started":"2024-02-01T08:08:41.964001Z","shell.execute_reply":"2024-02-01T08:08:42.032122Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_data=pd.read_csv(\"/kaggle/input/kidney-modified-dataset/Kidney_dataset_Modified.csv\").iloc[:, 1:]","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:24:41.350483Z","iopub.execute_input":"2024-02-01T08:24:41.350901Z","iopub.status.idle":"2024-02-01T08:24:41.368053Z","shell.execute_reply.started":"2024-02-01T08:24:41.35087Z","shell.execute_reply":"2024-02-01T08:24:41.366365Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Apply EM technique","metadata":{}},{"cell_type":"code","source":"pip install impyute","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:35:14.938458Z","iopub.execute_input":"2024-02-01T08:35:14.938938Z","iopub.status.idle":"2024-02-01T08:35:29.59235Z","shell.execute_reply.started":"2024-02-01T08:35:14.938904Z","shell.execute_reply":"2024-02-01T08:35:29.590786Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import impyute as impy","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:35:36.664171Z","iopub.execute_input":"2024-02-01T08:35:36.664641Z","iopub.status.idle":"2024-02-01T08:35:36.683431Z","shell.execute_reply.started":"2024-02-01T08:35:36.664608Z","shell.execute_reply":"2024-02-01T08:35:36.681893Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"imputeddata=impy.em(df_data.values, loops=1000)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:35:55.905282Z","iopub.execute_input":"2024-02-01T08:35:55.905709Z","iopub.status.idle":"2024-02-01T08:35:56.246247Z","shell.execute_reply.started":"2024-02-01T08:35:55.905677Z","shell.execute_reply":"2024-02-01T08:35:56.245191Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_data=pd.DataFrame(imputeddata) ","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:36:10.234172Z","iopub.execute_input":"2024-02-01T08:36:10.235253Z","iopub.status.idle":"2024-02-01T08:36:10.241888Z","shell.execute_reply.started":"2024-02-01T08:36:10.235213Z","shell.execute_reply":"2024-02-01T08:36:10.240266Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#df_data=df_data.fillna(0)\n#df_data.to_csv(\"newwdata_fi10test17.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:04:11.310375Z","iopub.execute_input":"2024-02-01T08:04:11.310783Z","iopub.status.idle":"2024-02-01T08:04:11.317966Z","shell.execute_reply.started":"2024-02-01T08:04:11.310746Z","shell.execute_reply":"2024-02-01T08:04:11.316448Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_data.columns = ['age', 'blood_pressure', 'specific_gravity', 'albumin', 'sugar', 'red_blood_cells', 'pus_cell',\n              'pus_cell_clumps', 'bacteria', 'blood_glucose_random', 'blood_urea', 'serum_creatinine', 'sodium',\n              'potassium', 'haemoglobin', 'packed_cell_volume', 'white_blood_cell_count', 'red_blood_cell_count',\n              'hypertension', 'diabetes_mellitus', 'coronary_artery_disease', 'appetite', 'peda_edema',\n              'anemia', 'class']","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:56:19.527381Z","iopub.execute_input":"2024-02-01T08:56:19.527934Z","iopub.status.idle":"2024-02-01T08:56:19.537683Z","shell.execute_reply.started":"2024-02-01T08:56:19.52789Z","shell.execute_reply":"2024-02-01T08:56:19.536447Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_data","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:56:22.944025Z","iopub.execute_input":"2024-02-01T08:56:22.94539Z","iopub.status.idle":"2024-02-01T08:56:22.995017Z","shell.execute_reply.started":"2024-02-01T08:56:22.945321Z","shell.execute_reply":"2024-02-01T08:56:22.993427Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_data.info()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:56:26.934889Z","iopub.execute_input":"2024-02-01T08:56:26.935385Z","iopub.status.idle":"2024-02-01T08:56:26.9524Z","shell.execute_reply.started":"2024-02-01T08:56:26.935349Z","shell.execute_reply":"2024-02-01T08:56:26.950923Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"border-radius: 10px; border: #ff001c solid; padding: 15px; margin-top: 15px; background-color: #ffffff00; font-size: \n            100%; text-align: left;\">\n    <b> 🚩 All columns assigned to numeric</b>\n</div>","metadata":{}},{"cell_type":"markdown","source":"# Modeling 🪄","metadata":{"execution":{"iopub.status.busy":"2023-08-22T02:34:09.351099Z","iopub.execute_input":"2023-08-22T02:34:09.351547Z","iopub.status.idle":"2023-08-22T02:34:09.356464Z","shell.execute_reply.started":"2023-08-22T02:34:09.35151Z","shell.execute_reply":"2023-08-22T02:34:09.355272Z"}}},{"cell_type":"markdown","source":"## Splitting Dataset","metadata":{}},{"cell_type":"code","source":"# Define Class as Target Variable, and the rest as feature variable\nX = df_data.drop(\"class\", axis=1)     # everything except 'class' column\ny = df_data['class']\n\n# Define the train dataset as 70% and test dataset as 30%\nX_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state = 1)\n\n# Confirm that the records returned for Train is about 70% and Test is about 30%\nprint(f\"'X' shape: {X_train.shape}\")\nprint(f\"'y' shape: {X_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:56:31.090256Z","iopub.execute_input":"2024-02-01T08:56:31.091358Z","iopub.status.idle":"2024-02-01T08:56:31.103355Z","shell.execute_reply.started":"2024-02-01T08:56:31.091267Z","shell.execute_reply":"2024-02-01T08:56:31.102111Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Apply Smote to balance the samples ","metadata":{}},{"cell_type":"code","source":"!pip install -U imbalanced-learn","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:41:46.872303Z","iopub.execute_input":"2024-02-01T08:41:46.87282Z","iopub.status.idle":"2024-02-01T08:42:00.900942Z","shell.execute_reply.started":"2024-02-01T08:41:46.872785Z","shell.execute_reply":"2024-02-01T08:42:00.899272Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Before OverSampling, counts of label '1': {}\".format(sum(Y_train == 1)))\nprint(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(Y_train == 0)))","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:56:37.033367Z","iopub.execute_input":"2024-02-01T08:56:37.034508Z","iopub.status.idle":"2024-02-01T08:56:37.042194Z","shell.execute_reply.started":"2024-02-01T08:56:37.034464Z","shell.execute_reply":"2024-02-01T08:56:37.040843Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\noversample = SMOTE()\nX_train, Y_train = oversample.fit_resample(X_train, Y_train)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:57:12.709054Z","iopub.execute_input":"2024-02-01T08:57:12.709889Z","iopub.status.idle":"2024-02-01T08:57:12.727131Z","shell.execute_reply.started":"2024-02-01T08:57:12.709847Z","shell.execute_reply":"2024-02-01T08:57:12.725447Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('After OverSampling, the shape of train_X: {}'.format(X_train.shape))\nprint('After OverSampling, the shape of train_y: {} \\n'.format(Y_train.shape))","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:57:29.436469Z","iopub.execute_input":"2024-02-01T08:57:29.437677Z","iopub.status.idle":"2024-02-01T08:57:29.444779Z","shell.execute_reply.started":"2024-02-01T08:57:29.437607Z","shell.execute_reply":"2024-02-01T08:57:29.44312Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"After OverSampling, counts of label '1': {}\".format(sum(Y_train == 1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(Y_train == 0)))","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:57:51.749527Z","iopub.execute_input":"2024-02-01T08:57:51.749956Z","iopub.status.idle":"2024-02-01T08:57:51.758486Z","shell.execute_reply.started":"2024-02-01T08:57:51.749926Z","shell.execute_reply":"2024-02-01T08:57:51.757231Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install wget \n\nimport wget\nwget.download('https://raw.githubusercontent.com/BorisMuzellec/MissingDataOT/master/utils.py')\n\nimport numpy as np\nimport pandas as pd\nfrom utils import *\nimport torch\nimport seaborn as sns\n\nimport pandas as pd\nimport missingno as msno\nhar = df_data\n#har1=har.iloc[:,:-1]\nhar1=har\n#msno.heatmap(har1)\n#msno.dendrogram(har1)\nhar1=har1.values\n#print('Shape Test:\\t{}\\n'.format(har1.shape))\nhar1\n\n\nhar1=har1.astype(float)\nhar1\n\n\ndef produce_NA(har1, p_miss, mecha=\"MAR\", opt=\"logistic\", p_obs=None, q=None):\n    to_torch = torch.is_tensor(har1) ## output a pytorch tensor, or a numpy array\n    if not to_torch:\n        har1 = har1.astype(np.float32)\n        har1 = torch.from_numpy(har1)\n    \n    if mecha == \"MAR\" and opt == \"logistic\":\n        mask = MAR_mask(har1, p_miss, p_obs).double()\n        print(\"mask values\")\n        print(mask)\n    elif mecha == \"MNAR\" and opt == \"logistic\":\n        mask = MNAR_mask_logistic(har1, p_miss, p_obs).double()\n    elif mecha == \"MNAR\" and opt == \"quantile\":\n        mask = MNAR_mask_quantiles(har1, p_miss, q, 1-p_obs).double()\n    elif mecha == \"MNAR\" and opt == \"selfmasked\":\n        mask = MNAR_self_mask_logistic(har1, p_miss).double()\n    else:\n        mask = (torch.rand(har1.shape) < p_miss).double()\n     \n    \n    har1_nas = har1.clone()\n    har1_nas[mask.bool()] = np.nan\n    \n    \n    \n    \n    return {'har1_init': har1.double(), 'har1_incomp': har1_nas.double(), 'mask': mask}\n\n\n\n\norig_dataset=df_data.drop('class',axis=1)\norig_dataset\nimport pandas as pd\nimport missingno as msno\nhar = orig_dataset\n#har1=har.iloc[:,:-1]\nhar1=har\n#msno.heatmap(har1)\n#msno.dendrogram(har1)\nhar1=har1.values\n#print('Shape Test:\\t{}\\n'.format(har1.shape))\nhar1\n\n\nhar1=har1.astype(float)\nhar1\n\nhar1_miss_mar = produce_NA(har1=har1, p_miss=0.99, mecha=\"MAR\", p_obs=0.5)\n \n\n\n#print(har1_mar) \nprint(har1_miss_mar['har1_init'])\nhar1_mar = har1_miss_mar['har1_incomp']\nprint(har1_mar)  \n#har1_mar = pd.DataFrame.from_dict(har1_mar)\nR_mcar = har1_miss_mar['mask']\nprint(R_mcar)\n \nprint(\"Percentage of generated missing values: \", (R_mcar.sum()).numpy()/np.prod(R_mcar.size())*100, \" %\")\n\nprint(har1_mar)\nprint('Shape Test:\\t{}\\n'.format(har1_mar.shape))\n\nimport torch\nimport pandas as pd\nimport numpy as np\n\n \nx_np = har1_mar.numpy()\nx_df = pd.DataFrame(x_np)\nx_df.to_csv('10mar_test.csv')\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\ntdf = pd.read_csv(\"./10mar_test.csv\").iloc[:, 1:]\ntdf.head()\n\ntdf.shape\n# Get null values and dataframe information  check for any missing data in data sets\nprint('Null Values In DataFrame: {}\\n'.format(tdf.isna().sum().sum()))\ntdf.info()\ntdf=tdf.fillna(0)\ntdf.to_csv(\"data_fil10.csv\")\n\ntdf\n\n\n\ntestdata = pd.read_csv('./10mar_test.csv').iloc[:, 1:] \n \ntestdata.head(10)\n#testdata=testdata.drop(['16'],axis=1)\ntestdata\n\nprint('Null Values In DataFrame: {}\\n'.format(testdata.isna().sum().sum()))\ntestdata.isnull().sum(0)\n\ntestdata=testdata.fillna(0)\ntestdata\nfrom sklearn.model_selection import train_test_split\n#kfold =sklearn.model_selection.KFold(n_splits=10)\n\nimport pandas as pd\n \nfrom sklearn.metrics import log_loss\n#seed=7\n#\n\n# importing voting classifier\nfrom sklearn.ensemble import VotingClassifier\n \n    \n#Edata10Mar = supp10_data2\nEdata10Mar =testdata \nEdata10Mar\nX = Edata10Mar  \ny= df_data[\"class\"] \nX\nfeature_cols = list(X) \ny\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = None)\nclf_dtc5 = DecisionTreeClassifier()\nclf_dtc5.fit(X_train, y_train)\nfeature_cols = list(X) \nimport six\nimport sys\nsys.modules['sklearn.externals.six'] = six\n#from six imporaccuracy_scoret StringIO\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\ndot_data = StringIO()\nexport_graphviz(clf_dtc5, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True, feature_names = feature_cols,class_names=['0','1','2'])\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png('ClassifierIoT1.png')\ni=Image(graph.create_png())\ni\n\n\n\ny_pred = clf_dtc5.predict(X_test)\nprint(y_pred)\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(y_test, y_pred)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-01T09:09:42.331366Z","iopub.execute_input":"2024-02-01T09:09:42.331886Z","iopub.status.idle":"2024-02-01T09:09:57.285726Z","shell.execute_reply.started":"2024-02-01T09:09:42.331847Z","shell.execute_reply":"2024-02-01T09:09:57.284167Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training Models","metadata":{}},{"cell_type":"code","source":"# Random Forest\nclf_rand_forest = RandomForestClassifier()\nclf_rand_forest.fit(X_train, Y_train)\n\n# SVM\nclf_svm = svm.SVC(kernel='linear')\nclf_svm.fit(X_train, Y_train)\n\n# KNN\nclf_knn = KNeighborsClassifier(n_neighbors=5)\nclf_knn.fit(X_train, Y_train)\n\n# Decision Tree\nclf_dtc = DecisionTreeClassifier()\nclf_dtc.fit(X_train, Y_train)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:46:11.494681Z","iopub.execute_input":"2024-02-01T08:46:11.495175Z","iopub.status.idle":"2024-02-01T08:46:15.900524Z","shell.execute_reply.started":"2024-02-01T08:46:11.495142Z","shell.execute_reply":"2024-02-01T08:46:15.899218Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model evaluation","metadata":{}},{"cell_type":"code","source":"# Printing of Model Evaluation Report\ndef print_std_model_evaulation_rpt(Y_test, Y_pred):\n    print(classification_report(Y_test, Y_pred))\n    print(f\"mean_absolute_error :- {mean_absolute_error(Y_test,Y_pred)}\")\n    print(f\"mean_absolute_error :- {mean_squared_error(Y_test,Y_pred, squared=False)}\")\n    cm1 = confusion_matrix(Y_test, Y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm1,display_labels=clf_rand_forest.classes_)\n    disp.plot()\n    plt.show()\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:46:20.565463Z","iopub.execute_input":"2024-02-01T08:46:20.565864Z","iopub.status.idle":"2024-02-01T08:46:20.574643Z","shell.execute_reply.started":"2024-02-01T08:46:20.565834Z","shell.execute_reply":"2024-02-01T08:46:20.572811Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Random Forest","metadata":{}},{"cell_type":"markdown","source":"#### Classification Report","metadata":{}},{"cell_type":"code","source":"# Random Forest\nY_pred = clf_rand_forest.predict(X_test)\nrand_forest_acc = accuracy_score(Y_test, Y_pred)\nprint_std_model_evaulation_rpt(Y_test, Y_pred)\n\n\nprint(rand_forest_acc)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:46:24.076231Z","iopub.execute_input":"2024-02-01T08:46:24.076726Z","iopub.status.idle":"2024-02-01T08:46:24.473075Z","shell.execute_reply.started":"2024-02-01T08:46:24.076673Z","shell.execute_reply":"2024-02-01T08:46:24.471782Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score,f1_score\nimport sklearn.metrics as metrics\n#print(classification_report(Y_test, y_pred))\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(Y_test, Y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:46:29.075677Z","iopub.execute_input":"2024-02-01T08:46:29.076145Z","iopub.status.idle":"2024-02-01T08:46:29.109487Z","shell.execute_reply.started":"2024-02-01T08:46:29.07611Z","shell.execute_reply":"2024-02-01T08:46:29.107787Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### SVM","metadata":{}},{"cell_type":"markdown","source":"#### Classification Report","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nX = df_data.drop(\"class\", axis=1)     # everything except 'class' column\ny = df_data['class']\n# Define the train dataset as 70% and test dataset as 30%\nX_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state = 1)\n\nclf_svm = svm.SVC(kernel='linear') #0.97\n# clf_svm = SVC(gamma='auto') # 0.59\n# clf_svm = SVC(kernel='poly') # 0.59\n# clf_svm = SVC(kernel='rbf',gamma=0.01) # 0.59\n# clf_svm.fit(X_test,Y_test)\nclf_svm.fit(X_train, Y_train)\n\nY_pred = clf_svm.predict(X_test)\nsvm_acc = accuracy_score(Y_test, Y_pred)\nprint_std_model_evaulation_rpt(Y_test, Y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:46:38.449143Z","iopub.execute_input":"2024-02-01T08:46:38.44964Z","iopub.status.idle":"2024-02-01T08:46:45.18702Z","shell.execute_reply.started":"2024-02-01T08:46:38.449608Z","shell.execute_reply":"2024-02-01T08:46:45.185968Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score,f1_score\nimport sklearn.metrics as metrics\n#print(classification_report(Y_test, y_pred))\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(Y_test, Y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:46:48.740614Z","iopub.execute_input":"2024-02-01T08:46:48.74103Z","iopub.status.idle":"2024-02-01T08:46:48.770949Z","shell.execute_reply.started":"2024-02-01T08:46:48.740999Z","shell.execute_reply":"2024-02-01T08:46:48.769411Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### KNN\nclf_knn = KNeighborsClassifier(n_neighbors=5)\nclf_knn.fit(X_train, Y_train)\nY_pred = clf_knn.predict(X_test)\nknn_acc = accuracy_score(Y_test, Y_pred)\nprint_std_model_evaulation_rpt(Y_test, Y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:46:53.014487Z","iopub.execute_input":"2024-02-01T08:46:53.014984Z","iopub.status.idle":"2024-02-01T08:46:53.490218Z","shell.execute_reply.started":"2024-02-01T08:46:53.014947Z","shell.execute_reply":"2024-02-01T08:46:53.488247Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score,f1_score\nimport sklearn.metrics as metrics\n#print(classification_report(Y_test, y_pred))\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(Y_test, Y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:47:08.868142Z","iopub.execute_input":"2024-02-01T08:47:08.868593Z","iopub.status.idle":"2024-02-01T08:47:08.902015Z","shell.execute_reply.started":"2024-02-01T08:47:08.868562Z","shell.execute_reply":"2024-02-01T08:47:08.900616Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Decision Tree\nY_pred = clf_dtc.predict(X_test)\ndtc_acc = accuracy_score(Y_test, Y_pred)\nprint_std_model_evaulation_rpt(Y_test, Y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:47:12.57549Z","iopub.execute_input":"2024-02-01T08:47:12.575908Z","iopub.status.idle":"2024-02-01T08:47:12.90562Z","shell.execute_reply.started":"2024-02-01T08:47:12.575878Z","shell.execute_reply":"2024-02-01T08:47:12.904084Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score,f1_score\nimport sklearn.metrics as metrics\n#print(classification_report(Y_test, y_pred))\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(Y_test, Y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:47:17.770356Z","iopub.execute_input":"2024-02-01T08:47:17.770797Z","iopub.status.idle":"2024-02-01T08:47:17.80687Z","shell.execute_reply.started":"2024-02-01T08:47:17.770766Z","shell.execute_reply":"2024-02-01T08:47:17.804927Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"models = pd.DataFrame({\n    'Model' : [ 'Random Forest Classifier', 'SVM Classifier', 'KNN Classifier', 'Decision Tree Classifier'],\n    'Score' : [rand_forest_acc, svm_acc,knn_acc, dtc_acc]\n})\n\n\nsorted_models = models.sort_values(by = 'Score', ascending = True)\n\nfig = px.bar(data_frame = sorted_models, x = 'Score', y = 'Model',\n       title = 'Models Comparison')\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:47:22.118836Z","iopub.execute_input":"2024-02-01T08:47:22.120107Z","iopub.status.idle":"2024-02-01T08:47:24.287316Z","shell.execute_reply.started":"2024-02-01T08:47:22.120051Z","shell.execute_reply":"2024-02-01T08:47:24.285132Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install astor\n","metadata":{"execution":{"iopub.status.busy":"2024-01-09T04:30:00.015126Z","iopub.execute_input":"2024-01-09T04:30:00.015673Z","iopub.status.idle":"2024-01-09T04:30:16.946809Z","shell.execute_reply.started":"2024-01-09T04:30:00.015635Z","shell.execute_reply":"2024-01-09T04:30:16.945216Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install skompiler\n","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:47:41.360462Z","iopub.execute_input":"2024-02-01T08:47:41.360893Z","iopub.status.idle":"2024-02-01T08:47:58.891571Z","shell.execute_reply.started":"2024-02-01T08:47:41.360861Z","shell.execute_reply":"2024-02-01T08:47:58.88981Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install pydotplus","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:47:58.895158Z","iopub.execute_input":"2024-02-01T08:47:58.895779Z","iopub.status.idle":"2024-02-01T08:48:16.106685Z","shell.execute_reply.started":"2024-02-01T08:47:58.895706Z","shell.execute_reply":"2024-02-01T08:48:16.105082Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = df_data.drop(\"class\", axis=1)     # everything except 'class' column\ny = df_data['class']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = None)\nclf_dtc.fit(X_train, y_train)\nfeature_cols = list(X) \nimport six\nimport sys\nsys.modules['sklearn.externals.six'] = six\n#from six imporaccuracy_scoret StringIO\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\ndot_data = StringIO()\nexport_graphviz(clf_dtc, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True, feature_names = feature_cols,class_names=['0','1','2'])\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png('ClassifierIoT1.png')\ni=Image(graph.create_png())\ni","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:48:16.10845Z","iopub.execute_input":"2024-02-01T08:48:16.108885Z","iopub.status.idle":"2024-02-01T08:48:16.796167Z","shell.execute_reply.started":"2024-02-01T08:48:16.108847Z","shell.execute_reply":"2024-02-01T08:48:16.795141Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = clf_dtc.predict(X_test)\nprint(y_pred)\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T08:48:16.798736Z","iopub.execute_input":"2024-02-01T08:48:16.799181Z","iopub.status.idle":"2024-02-01T08:48:16.834131Z","shell.execute_reply.started":"2024-02-01T08:48:16.799144Z","shell.execute_reply":"2024-02-01T08:48:16.833078Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create a subspace classifiers \n","metadata":{}},{"cell_type":"code","source":"df_data1=pd.read_csv(\"/kaggle/input/kidney-modified-dataset/Kidney_dataset_Modified.csv\").iloc[:, 1:]","metadata":{"execution":{"iopub.status.busy":"2024-01-09T04:30:52.212361Z","iopub.execute_input":"2024-01-09T04:30:52.212793Z","iopub.status.idle":"2024-01-09T04:30:52.231073Z","shell.execute_reply.started":"2024-01-09T04:30:52.212752Z","shell.execute_reply":"2024-01-09T04:30:52.229629Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_data1","metadata":{"execution":{"iopub.status.busy":"2024-01-09T04:30:52.233186Z","iopub.execute_input":"2024-01-09T04:30:52.235336Z","iopub.status.idle":"2024-01-09T04:30:52.290374Z","shell.execute_reply.started":"2024-01-09T04:30:52.235285Z","shell.execute_reply":"2024-01-09T04:30:52.289074Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_data1=df_data1.fillna(0)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T04:30:52.29211Z","iopub.execute_input":"2024-01-09T04:30:52.292637Z","iopub.status.idle":"2024-01-09T04:30:52.300352Z","shell.execute_reply.started":"2024-01-09T04:30:52.29259Z","shell.execute_reply":"2024-01-09T04:30:52.298919Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"columns = ['age','blood_pressure','sugar','red_blood_cells ',\n'pus_cell','pus_cell_clumps','bacteria','blood_glucose_random','blood_urea','potassium','white_blood_cell_count','red_blood_cell_count','hypertension','coronary_artery_disease','peda_edema','class']\ndata2 = pd.DataFrame(df_data1, columns=columns)\ndata2","metadata":{"execution":{"iopub.status.busy":"2024-01-08T08:50:22.033449Z","iopub.execute_input":"2024-01-08T08:50:22.033832Z","iopub.status.idle":"2024-01-08T08:50:22.070972Z","shell.execute_reply.started":"2024-01-08T08:50:22.0338Z","shell.execute_reply":"2024-01-08T08:50:22.070021Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data2=data2.fillna(0)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T08:52:52.46331Z","iopub.execute_input":"2024-01-08T08:52:52.463715Z","iopub.status.idle":"2024-01-08T08:52:52.469574Z","shell.execute_reply.started":"2024-01-08T08:52:52.463684Z","shell.execute_reply":"2024-01-08T08:52:52.468619Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = data2.drop(\"class\", axis=1)     # everything except 'class' column\ny = data2['class']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = None)\nclf_dtc2 = DecisionTreeClassifier()\nclf_dtc2.fit(X_train, y_train)\nfeature_cols = list(X) \nimport six\nimport sys\nsys.modules['sklearn.externals.six'] = six\n#from six imporaccuracy_scoret StringIO\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\ndot_data = StringIO()\nexport_graphviz(clf_dtc2, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True, feature_names = feature_cols,class_names=['0','1','2'])\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png('ClassifierIoT1.png')\ni=Image(graph.create_png())\ni","metadata":{"execution":{"iopub.status.busy":"2024-01-08T08:52:54.469787Z","iopub.execute_input":"2024-01-08T08:52:54.470138Z","iopub.status.idle":"2024-01-08T08:52:55.625002Z","shell.execute_reply.started":"2024-01-08T08:52:54.470113Z","shell.execute_reply":"2024-01-08T08:52:55.624091Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = clf_dtc2.predict(X_test)\nprint(y_pred)\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T08:53:06.927972Z","iopub.execute_input":"2024-01-08T08:53:06.928353Z","iopub.status.idle":"2024-01-08T08:53:06.954008Z","shell.execute_reply.started":"2024-01-08T08:53:06.928322Z","shell.execute_reply":"2024-01-08T08:53:06.95312Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modified Dataset -2","metadata":{}},{"cell_type":"code","source":"columns = ['specific_gravity','albumin','serum_creatinine','sodium',\n'haemoglobin','packed_cell_volume','diabetes_mellitus','appetite','anemia','age','blood_pressure','red_blood_cells','pus_cell','pus_cell_clumps','bacteria','coronary_artery_disease','class']\ndata3 = pd.DataFrame(df_data1, columns=columns)\ndata3\n","metadata":{"execution":{"iopub.status.busy":"2024-01-08T09:29:12.833386Z","iopub.execute_input":"2024-01-08T09:29:12.834277Z","iopub.status.idle":"2024-01-08T09:29:12.87072Z","shell.execute_reply.started":"2024-01-08T09:29:12.834245Z","shell.execute_reply":"2024-01-08T09:29:12.869776Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data3=data3.fillna(0)\n\nX = data3.drop(\"class\", axis=1)     # everything except 'class' column\ny = data3['class']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = None)\nclf_dtc3 = DecisionTreeClassifier()\nclf_dtc3.fit(X_train, y_train)\nfeature_cols = list(X) \nimport six\nimport sys\nsys.modules['sklearn.externals.six'] = six\n#from six imporaccuracy_scoret StringIO\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\ndot_data = StringIO()\nexport_graphviz(clf_dtc3, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True, feature_names = feature_cols,class_names=['0','1','2'])\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png('ClassifierIoT1.png')\ni=Image(graph.create_png())\ni\n\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-08T09:32:43.296359Z","iopub.execute_input":"2024-01-08T09:32:43.29675Z","iopub.status.idle":"2024-01-08T09:32:43.743898Z","shell.execute_reply.started":"2024-01-08T09:32:43.296707Z","shell.execute_reply":"2024-01-08T09:32:43.742909Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = clf_dtc3.predict(X_test)\nprint(y_pred)\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(y_test, y_pred)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-08T09:32:48.634332Z","iopub.execute_input":"2024-01-08T09:32:48.635064Z","iopub.status.idle":"2024-01-08T09:32:48.659102Z","shell.execute_reply.started":"2024-01-08T09:32:48.635029Z","shell.execute_reply":"2024-01-08T09:32:48.658036Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modified Datast 3\n","metadata":{}},{"cell_type":"code","source":"columns = ['specific_gravity','appetite','anemia','age',\n'blood_pressure','red_blood_cells','pus_cell','pus_cell_clumps ','bacteria','coronary_artery_disease  ','blood_pressure','red_blood_cells','pus_cell','pus_cell_clumps','bacteria','coronary_artery_disease','class']\ndata4 = pd.DataFrame(df_data1, columns=columns)\ndata4\n","metadata":{"execution":{"iopub.status.busy":"2024-01-08T09:43:23.338945Z","iopub.execute_input":"2024-01-08T09:43:23.339897Z","iopub.status.idle":"2024-01-08T09:43:23.381473Z","shell.execute_reply.started":"2024-01-08T09:43:23.339856Z","shell.execute_reply":"2024-01-08T09:43:23.380562Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data4=data4.fillna(0)\n\nX = data4.drop(\"class\", axis=1)     # everything except 'class' column\ny = data4['class']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = None)\nclf_dtc4 = DecisionTreeClassifier()\nclf_dtc4.fit(X_train, y_train)\nfeature_cols = list(X) \nimport six\nimport sys\nsys.modules['sklearn.externals.six'] = six\n#from six imporaccuracy_scoret StringIO\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\ndot_data = StringIO()\nexport_graphviz(clf_dtc4, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True, feature_names = feature_cols,class_names=['0','1','2'])\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png('ClassifierIoT3.png')\ni=Image(graph.create_png())\ni","metadata":{"execution":{"iopub.status.busy":"2024-01-08T09:46:19.633502Z","iopub.execute_input":"2024-01-08T09:46:19.634233Z","iopub.status.idle":"2024-01-08T09:46:20.175713Z","shell.execute_reply.started":"2024-01-08T09:46:19.634198Z","shell.execute_reply":"2024-01-08T09:46:20.174699Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = clf_dtc4.predict(X_test)\nprint(y_pred)\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T09:46:33.142212Z","iopub.execute_input":"2024-01-08T09:46:33.143101Z","iopub.status.idle":"2024-01-08T09:46:33.169763Z","shell.execute_reply.started":"2024-01-08T09:46:33.143068Z","shell.execute_reply":"2024-01-08T09:46:33.168793Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modifed Dataset -4","metadata":{}},{"cell_type":"code","source":"columns = ['appetite','anemia','pus_cell_clumps ','bacteria','coronary_artery_disease','class']\ndata5 = pd.DataFrame(df_data1, columns=columns)\ndata5","metadata":{"execution":{"iopub.status.busy":"2024-01-08T09:50:19.614337Z","iopub.execute_input":"2024-01-08T09:50:19.615122Z","iopub.status.idle":"2024-01-08T09:50:19.635543Z","shell.execute_reply.started":"2024-01-08T09:50:19.615085Z","shell.execute_reply":"2024-01-08T09:50:19.634564Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data5=data5.fillna(0)\n\nX = data5.drop(\"class\", axis=1)     # everything except 'class' column\ny = data5['class']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = None)\nclf_dtc5 = DecisionTreeClassifier()\nclf_dtc5.fit(X_train, y_train)\nfeature_cols = list(X) \nimport six\nimport sys\nsys.modules['sklearn.externals.six'] = six\n#from six imporaccuracy_scoret StringIO\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\ndot_data = StringIO()\nexport_graphviz(clf_dtc5, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True, feature_names = feature_cols,class_names=['0','1','2'])\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png('ClassifierIoT1.png')\ni=Image(graph.create_png())\ni","metadata":{"execution":{"iopub.status.busy":"2024-01-08T09:51:21.782335Z","iopub.execute_input":"2024-01-08T09:51:21.782732Z","iopub.status.idle":"2024-01-08T09:51:22.155283Z","shell.execute_reply.started":"2024-01-08T09:51:21.782701Z","shell.execute_reply":"2024-01-08T09:51:22.154369Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = clf_dtc5.predict(X_test)\nprint(y_pred)\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T09:51:27.708715Z","iopub.execute_input":"2024-01-08T09:51:27.709082Z","iopub.status.idle":"2024-01-08T09:51:27.733205Z","shell.execute_reply.started":"2024-01-08T09:51:27.709056Z","shell.execute_reply":"2024-01-08T09:51:27.732215Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Save the  models\n","metadata":{}},{"cell_type":"code","source":"import pickle\n#pickle.dump(clf_dtc2, open('clf_dtc2', 'wb'))\nclf_dtc2 = pickle.load(open('clf_dtc2', 'rb'))\n#pickled_model.predict(X_test)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-09T04:31:14.771766Z","iopub.execute_input":"2024-01-09T04:31:14.772382Z","iopub.status.idle":"2024-01-09T04:31:14.780449Z","shell.execute_reply.started":"2024-01-09T04:31:14.772333Z","shell.execute_reply":"2024-01-09T04:31:14.77916Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\n#pickle.dump(clf_dtc3, open('clf_dtc3', 'wb'))\nclf_dtc3 = pickle.load(open('clf_dtc3', 'rb'))\n#pickled_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T06:06:03.848256Z","iopub.execute_input":"2024-01-09T06:06:03.848834Z","iopub.status.idle":"2024-01-09T06:06:03.857072Z","shell.execute_reply.started":"2024-01-09T06:06:03.848777Z","shell.execute_reply":"2024-01-09T06:06:03.855647Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\n#pickle.dump(clf_dtc4, open('clf_dtc4', 'wb'))\nclf_dtc4 = pickle.load(open('clf_dtc4', 'rb'))\n#pickled_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T04:31:23.565072Z","iopub.execute_input":"2024-01-09T04:31:23.565577Z","iopub.status.idle":"2024-01-09T04:31:23.572657Z","shell.execute_reply.started":"2024-01-09T04:31:23.565532Z","shell.execute_reply":"2024-01-09T04:31:23.571321Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\n#pickle.dump(clf_dtc5, open('clf_dtc5', 'wb'))\nclf_dtc5 = pickle.load(open('clf_dtc5', 'rb'))\n#pickled_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T04:31:28.367304Z","iopub.execute_input":"2024-01-09T04:31:28.367808Z","iopub.status.idle":"2024-01-09T04:31:28.374865Z","shell.execute_reply.started":"2024-01-09T04:31:28.367768Z","shell.execute_reply":"2024-01-09T04:31:28.373562Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Now form a Ensemble Classifier ","metadata":{}},{"cell_type":"code","source":"df_data1","metadata":{"execution":{"iopub.status.busy":"2024-01-09T04:31:31.398654Z","iopub.execute_input":"2024-01-09T04:31:31.399452Z","iopub.status.idle":"2024-01-09T04:31:31.457945Z","shell.execute_reply.started":"2024-01-09T04:31:31.39941Z","shell.execute_reply":"2024-01-09T04:31:31.456683Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"orig_dataset=df_data1.drop('class',axis=1)\norig_dataset","metadata":{"execution":{"iopub.status.busy":"2024-01-08T10:12:44.888126Z","iopub.execute_input":"2024-01-08T10:12:44.888505Z","iopub.status.idle":"2024-01-08T10:12:44.931299Z","shell.execute_reply.started":"2024-01-08T10:12:44.888474Z","shell.execute_reply":"2024-01-08T10:12:44.930227Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generate diffe missing values ","metadata":{}},{"cell_type":"code","source":"!pip install wget \n\nimport wget\nwget.download('https://raw.githubusercontent.com/BorisMuzellec/MissingDataOT/master/utils.py')\n\nimport numpy as np\nimport pandas as pd\nfrom utils import *\nimport torch\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2024-01-09T05:32:11.608427Z","iopub.execute_input":"2024-01-09T05:32:11.608972Z","iopub.status.idle":"2024-01-09T05:32:33.356305Z","shell.execute_reply.started":"2024-01-09T05:32:11.608936Z","shell.execute_reply":"2024-01-09T05:32:33.35481Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport missingno as msno\nhar = orig_dataset\n#har1=har.iloc[:,:-1]\nhar1=har\n#msno.heatmap(har1)\n#msno.dendrogram(har1)\nhar1=har1.values\n#print('Shape Test:\\t{}\\n'.format(har1.shape))\nhar1\n\n\nhar1=har1.astype(float)\nhar1\n","metadata":{"execution":{"iopub.status.busy":"2024-01-08T10:13:50.271645Z","iopub.execute_input":"2024-01-08T10:13:50.272457Z","iopub.status.idle":"2024-01-08T10:13:50.287152Z","shell.execute_reply.started":"2024-01-08T10:13:50.272418Z","shell.execute_reply":"2024-01-08T10:13:50.286218Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def produce_NA(har1, p_miss, mecha=\"MAR\", opt=\"logistic\", p_obs=None, q=None):\n    to_torch = torch.is_tensor(har1) ## output a pytorch tensor, or a numpy array\n    if not to_torch:\n        har1 = har1.astype(np.float32)\n        har1 = torch.from_numpy(har1)\n    \n    if mecha == \"MAR\" and opt == \"logistic\":\n        mask = MAR_mask(har1, p_miss, p_obs).double()\n        print(\"mask values\")\n        print(mask)\n    elif mecha == \"MNAR\" and opt == \"logistic\":\n        mask = MNAR_mask_logistic(har1, p_miss, p_obs).double()\n    elif mecha == \"MNAR\" and opt == \"quantile\":\n        mask = MNAR_mask_quantiles(har1, p_miss, q, 1-p_obs).double()\n    elif mecha == \"MNAR\" and opt == \"selfmasked\":\n        mask = MNAR_self_mask_logistic(har1, p_miss).double()\n    else:\n        mask = (torch.rand(har1.shape) < p_miss).double()\n     \n    \n    har1_nas = har1.clone()\n    har1_nas[mask.bool()] = np.nan\n    \n    \n    \n    \n    return {'har1_init': har1.double(), 'har1_incomp': har1_nas.double(), 'mask': mask}","metadata":{"execution":{"iopub.status.busy":"2024-01-08T10:14:09.720582Z","iopub.execute_input":"2024-01-08T10:14:09.721489Z","iopub.status.idle":"2024-01-08T10:14:09.730547Z","shell.execute_reply.started":"2024-01-08T10:14:09.721453Z","shell.execute_reply":"2024-01-08T10:14:09.72955Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"har1_miss_mar = produce_NA(har1=har1, p_miss=0.10, mecha=\"MAR\", p_obs=0.5)\n \n\n\n#print(har1_mar) \nprint(har1_miss_mar['har1_init'])\nhar1_mar = har1_miss_mar['har1_incomp']\nprint(har1_mar)  \n#har1_mar = pd.DataFrame.from_dict(har1_mar)\nR_mcar = har1_miss_mar['mask']\nprint(R_mcar)\n \n\nprint(\"Percentage of generated missing values: \", (R_mcar.sum()).numpy()/np.prod(R_mcar.size())*100, \" %\")\n\nprint(har1_mar)\nprint('Shape Test:\\t{}\\n'.format(har1_mar.shape))\n\nimport torch\nimport pandas as pd\nimport numpy as np\n\n \nx_np = har1_mar.numpy()\nx_df = pd.DataFrame(x_np)\nx_df.to_csv('10mar_test.csv')\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\ntdf = pd.read_csv(\"./10mar_test.csv\").iloc[:, 1:]\ntdf.head()\n\ntdf.shape\n# Get null values and dataframe information  check for any missing data in data sets\nprint('Null Values In DataFrame: {}\\n'.format(tdf.isna().sum().sum()))\ntdf.info()\ntdf=tdf.fillna(0)\ntdf.to_csv(\"data_fil10.csv\")\n\ntdf\n\n\n\ntestdata = pd.read_csv('./10mar_test.csv').iloc[:, 1:] \n \ntestdata.head(10)\n#testdata=testdata.drop(['16'],axis=1)\ntestdata\n\nprint('Null Values In DataFrame: {}\\n'.format(testdata.isna().sum().sum()))\ntestdata.isnull().sum(0)\n\ntestdata=testdata.fillna(0)\ntestdata\n","metadata":{"execution":{"iopub.status.busy":"2024-01-08T10:15:20.008245Z","iopub.execute_input":"2024-01-08T10:15:20.009276Z","iopub.status.idle":"2024-01-08T10:15:20.253968Z","shell.execute_reply.started":"2024-01-08T10:15:20.009241Z","shell.execute_reply":"2024-01-08T10:15:20.253065Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n#kfold =sklearn.model_selection.KFold(n_splits=10)\n\nimport pandas as pd\n \nfrom sklearn.metrics import log_loss\n#seed=7\n#\n\n# importing voting classifier\nfrom sklearn.ensemble import VotingClassifier\n \n    \n#Edata10Mar = supp10_data2\nEdata10Mar =testdata \nEdata10Mar\n\nX = Edata10Mar \ny= df_data1[\"class\"] \nX\nfeature_cols = list(X) \ny\n# split data\nX_train, X_test, Y_train, Y_test = train_test_split(X, y)\n\n\n\n\n\nestimators = []\nestimators.append(('c1',clf_dtc2))\nestimators.append(('c2',clf_dtc3))\nestimators.append(('c3',clf_dtc4))\nestimators.append(('c4',clf_dtc5))\n\n\n'''voting = VotingClassifier(estimators=estimators,voting='hard')\nvot_hard=voting.fit(X_train, Y_train)\n\ny_pred=vot_hard.predict(X_test)\nprint(y_pred)\nscore=accuracy_score(Y_test,y_pred)\n#print(\"hard voting score %d\" % score)\nprint(score)'''\n\n\n\n# Voting Classifier with soft voting\nvot_soft = VotingClassifier(estimators = estimators, voting ='soft')\nvot_soft.fit(X_train, Y_train)\ny_pred = vot_soft.predict(X_test)\nprint(y_pred)\n# using accuracy_score\nsscore = accuracy_score(Y_test, y_pred)\n#print(\"Soft Voting Score % d\" % score)\nprint(sscore)\n\nfrom sklearn.metrics import classification_report\n\n#print(classification_report(Y_test, y_pred))\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(Y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T10:18:30.486882Z","iopub.execute_input":"2024-01-08T10:18:30.487235Z","iopub.status.idle":"2024-01-08T10:18:30.53353Z","shell.execute_reply.started":"2024-01-08T10:18:30.48721Z","shell.execute_reply":"2024-01-08T10:18:30.532531Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **for 20% missing values**\n","metadata":{}},{"cell_type":"code","source":"har1_miss_mar = produce_NA(har1=har1, p_miss=0.20, mecha=\"MAR\", p_obs=0.5)\n \n\n\n#print(har1_mar) \nprint(har1_miss_mar['har1_init'])\nhar1_mar = har1_miss_mar['har1_incomp']\nprint(har1_mar)  \n#har1_mar = pd.DataFrame.from_dict(har1_mar)\nR_mcar = har1_miss_mar['mask']\nprint(R_mcar)\n \n\nprint(\"Percentage of generated missing values: \", (R_mcar.sum()).numpy()/np.prod(R_mcar.size())*100, \" %\")\n\nprint(har1_mar)\nprint('Shape Test:\\t{}\\n'.format(har1_mar.shape))\n\nimport torch\nimport pandas as pd\nimport numpy as np\n\n \nx_np = har1_mar.numpy()\nx_df = pd.DataFrame(x_np)\nx_df.to_csv('10mar_test.csv')\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\ntdf = pd.read_csv(\"./10mar_test.csv\").iloc[:, 1:]\ntdf.head()\n\ntdf.shape\n# Get null values and dataframe information  check for any missing data in data sets\nprint('Null Values In DataFrame: {}\\n'.format(tdf.isna().sum().sum()))\ntdf.info()\ntdf=tdf.fillna(0)\ntdf.to_csv(\"data_fil10.csv\")\n\ntdf\n\n\n\ntestdata = pd.read_csv('./10mar_test.csv').iloc[:, 1:] \n \ntestdata.head(10)\n#testdata=testdata.drop(['16'],axis=1)\ntestdata\n\nprint('Null Values In DataFrame: {}\\n'.format(testdata.isna().sum().sum()))\ntestdata.isnull().sum(0)\n\ntestdata=testdata.fillna(0)\ntestdata\n\n\n\nfrom sklearn.model_selection import train_test_split\n#kfold =sklearn.model_selection.KFold(n_splits=10)\n\nimport pandas as pd\n \nfrom sklearn.metrics import log_loss\n#seed=7\n#\n\n# importing voting classifier\nfrom sklearn.ensemble import VotingClassifier\n \n    \n#Edata10Mar = supp10_data2\nEdata10Mar =testdata \nEdata10Mar\n\nX = Edata10Mar \ny= df_data1[\"class\"] \nX\nfeature_cols = list(X) \ny\n# split data\nX_train, X_test, Y_train, Y_test = train_test_split(X, y)\n\n\n\n\n\nestimators = []\nestimators.append(('c1',clf_dtc2))\nestimators.append(('c2',clf_dtc3))\nestimators.append(('c3',clf_dtc4))\nestimators.append(('c4',clf_dtc5))\n\n\n'''voting = VotingClassifier(estimators=estimators,voting='hard')\nvot_hard=voting.fit(X_train, Y_train)\n\ny_pred=vot_hard.predict(X_test)\nprint(y_pred)\nscore=accuracy_score(Y_test,y_pred)\n#print(\"hard voting score %d\" % score)\nprint(score)'''\n\n\n\n# Voting Classifier with soft voting\nvot_soft = VotingClassifier(estimators = estimators, voting ='soft')\nvot_soft.fit(X_train, Y_train)\ny_pred = vot_soft.predict(X_test)\nprint(y_pred)\n# using accuracy_score\nsscore = accuracy_score(Y_test, y_pred)\n#print(\"Soft Voting Score % d\" % score)\nprint(sscore)\n\nfrom sklearn.metrics import classification_report\n\n#print(classification_report(Y_test, y_pred))\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(Y_test, y_pred)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-08T10:25:59.205036Z","iopub.execute_input":"2024-01-08T10:25:59.205881Z","iopub.status.idle":"2024-01-08T10:25:59.320715Z","shell.execute_reply.started":"2024-01-08T10:25:59.205844Z","shell.execute_reply":"2024-01-08T10:25:59.319798Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# for 30% ","metadata":{}},{"cell_type":"code","source":"har1_miss_mar = produce_NA(har1=har1, p_miss=0.30, mecha=\"MAR\", p_obs=0.5)\n \n\n\n#print(har1_mar) \nprint(har1_miss_mar['har1_init'])\nhar1_mar = har1_miss_mar['har1_incomp']\nprint(har1_mar)  \n#har1_mar = pd.DataFrame.from_dict(har1_mar)\nR_mcar = har1_miss_mar['mask']\nprint(R_mcar)\n \n\nprint(\"Percentage of generated missing values: \", (R_mcar.sum()).numpy()/np.prod(R_mcar.size())*100, \" %\")\n\nprint(har1_mar)\nprint('Shape Test:\\t{}\\n'.format(har1_mar.shape))\n\nimport torch\nimport pandas as pd\nimport numpy as np\n\n \nx_np = har1_mar.numpy()\nx_df = pd.DataFrame(x_np)\nx_df.to_csv('10mar_test.csv')\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\ntdf = pd.read_csv(\"./10mar_test.csv\").iloc[:, 1:]\ntdf.head()\n\ntdf.shape\n# Get null values and dataframe information  check for any missing data in data sets\nprint('Null Values In DataFrame: {}\\n'.format(tdf.isna().sum().sum()))\ntdf.info()\ntdf=tdf.fillna(0)\ntdf.to_csv(\"data_fil10.csv\")\n\ntdf\n\n\n\ntestdata = pd.read_csv('./10mar_test.csv').iloc[:, 1:] \n \ntestdata.head(10)\n#testdata=testdata.drop(['16'],axis=1)\ntestdata\n\nprint('Null Values In DataFrame: {}\\n'.format(testdata.isna().sum().sum()))\ntestdata.isnull().sum(0)\n\ntestdata=testdata.fillna(0)\ntestdata\n\n\n\nfrom sklearn.model_selection import train_test_split\n#kfold =sklearn.model_selection.KFold(n_splits=10)\n\nimport pandas as pd\n \nfrom sklearn.metrics import log_loss\n#seed=7\n#\n\n# importing voting classifier\nfrom sklearn.ensemble import VotingClassifier\n \n    \n#Edata10Mar = supp10_data2\nEdata10Mar =testdata \nEdata10Mar\n\nX = Edata10Mar \ny= df_data1[\"class\"] \nX\nfeature_cols = list(X) \ny\n# split data\nX_train, X_test, Y_train, Y_test = train_test_split(X, y)\n\n\n\n\n\nestimators = []\nestimators.append(('c1',clf_dtc2))\nestimators.append(('c2',clf_dtc3))\nestimators.append(('c3',clf_dtc4))\nestimators.append(('c4',clf_dtc5))\n\n\n'''voting = VotingClassifier(estimators=estimators,voting='hard')\nvot_hard=voting.fit(X_train, Y_train)\n\ny_pred=vot_hard.predict(X_test)\nprint(y_pred)\nscore=accuracy_score(Y_test,y_pred)\n#print(\"hard voting score %d\" % score)\nprint(score)'''\n\n\n\n# Voting Classifier with soft voting\nvot_soft = VotingClassifier(estimators = estimators, voting ='soft')\nvot_soft.fit(X_train, Y_train)\ny_pred = vot_soft.predict(X_test)\nprint(y_pred)\n# using accuracy_score\nsscore = accuracy_score(Y_test, y_pred)\n#print(\"Soft Voting Score % d\" % score)\nprint(sscore)\n\nfrom sklearn.metrics import classification_report\n\n#print(classification_report(Y_test, y_pred))\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(Y_test, y_pred)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-08T10:26:36.734691Z","iopub.execute_input":"2024-01-08T10:26:36.735608Z","iopub.status.idle":"2024-01-08T10:26:36.84144Z","shell.execute_reply.started":"2024-01-08T10:26:36.735575Z","shell.execute_reply":"2024-01-08T10:26:36.840393Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# For 40%","metadata":{}},{"cell_type":"code","source":"har1_miss_mar = produce_NA(har1=har1, p_miss=0.40, mecha=\"MAR\", p_obs=0.5)\n \n\n\n#print(har1_mar) \nprint(har1_miss_mar['har1_init'])\nhar1_mar = har1_miss_mar['har1_incomp']\nprint(har1_mar)  \n#har1_mar = pd.DataFrame.from_dict(har1_mar)\nR_mcar = har1_miss_mar['mask']\nprint(R_mcar)\n \n\nprint(\"Percentage of generated missing values: \", (R_mcar.sum()).numpy()/np.prod(R_mcar.size())*100, \" %\")\n\nprint(har1_mar)\nprint('Shape Test:\\t{}\\n'.format(har1_mar.shape))\n\nimport torch\nimport pandas as pd\nimport numpy as np\n\n \nx_np = har1_mar.numpy()\nx_df = pd.DataFrame(x_np)\nx_df.to_csv('10mar_test.csv')\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\ntdf = pd.read_csv(\"./10mar_test.csv\").iloc[:, 1:]\ntdf.head()\n\ntdf.shape\n# Get null values and dataframe information  check for any missing data in data sets\nprint('Null Values In DataFrame: {}\\n'.format(tdf.isna().sum().sum()))\ntdf.info()\ntdf=tdf.fillna(0)\ntdf.to_csv(\"data_fil10.csv\")\n\ntdf\n\n\n\ntestdata = pd.read_csv('./10mar_test.csv').iloc[:, 1:] \n \ntestdata.head(10)\n#testdata=testdata.drop(['16'],axis=1)\ntestdata\n\nprint('Null Values In DataFrame: {}\\n'.format(testdata.isna().sum().sum()))\ntestdata.isnull().sum(0)\n\ntestdata=testdata.fillna(0)\ntestdata\n\n\n\nfrom sklearn.model_selection import train_test_split\n#kfold =sklearn.model_selection.KFold(n_splits=10)\n\nimport pandas as pd\n \nfrom sklearn.metrics import log_loss\n#seed=7\n#\n\n# importing voting classifier\nfrom sklearn.ensemble import VotingClassifier\n \n    \n#Edata10Mar = supp10_data2\nEdata10Mar =testdata \nEdata10Mar\n\nX = Edata10Mar \ny= df_data1[\"class\"] \nX\nfeature_cols = list(X) \ny\n# split data\nX_train, X_test, Y_train, Y_test = train_test_split(X, y)\n\n\n\n\n\nestimators = []\nestimators.append(('c1',clf_dtc2))\nestimators.append(('c2',clf_dtc3))\nestimators.append(('c3',clf_dtc4))\nestimators.append(('c4',clf_dtc5))\n\n\n'''voting = VotingClassifier(estimators=estimators,voting='hard')\nvot_hard=voting.fit(X_train, Y_train)\n\ny_pred=vot_hard.predict(X_test)\nprint(y_pred)\nscore=accuracy_score(Y_test,y_pred)\n#print(\"hard voting score %d\" % score)\nprint(score)'''\n\n\n\n# Voting Classifier with soft voting\nvot_soft = VotingClassifier(estimators = estimators, voting ='soft')\nvot_soft.fit(X_train, Y_train)\ny_pred = vot_soft.predict(X_test)\nprint(y_pred)\n# using accuracy_score\nsscore = accuracy_score(Y_test, y_pred)\n#print(\"Soft Voting Score % d\" % score)\nprint(sscore)\n\nfrom sklearn.metrics import classification_report\n\n#print(classification_report(Y_test, y_pred))\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(Y_test, y_pred)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-08T10:27:04.802108Z","iopub.execute_input":"2024-01-08T10:27:04.802513Z","iopub.status.idle":"2024-01-08T10:27:04.909617Z","shell.execute_reply.started":"2024-01-08T10:27:04.802481Z","shell.execute_reply":"2024-01-08T10:27:04.908728Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# For 50%","metadata":{}},{"cell_type":"code","source":"har1_miss_mar = produce_NA(har1=har1, p_miss=0.50, mecha=\"MAR\", p_obs=0.5)\n \n\n\n#print(har1_mar) \nprint(har1_miss_mar['har1_init'])\nhar1_mar = har1_miss_mar['har1_incomp']\nprint(har1_mar)  \n#har1_mar = pd.DataFrame.from_dict(har1_mar)\nR_mcar = har1_miss_mar['mask']\nprint(R_mcar)\n \n\nprint(\"Percentage of generated missing values: \", (R_mcar.sum()).numpy()/np.prod(R_mcar.size())*100, \" %\")\n\nprint(har1_mar)\nprint('Shape Test:\\t{}\\n'.format(har1_mar.shape))\n\nimport torch\nimport pandas as pd\nimport numpy as np\n\n \nx_np = har1_mar.numpy()\nx_df = pd.DataFrame(x_np)\nx_df.to_csv('10mar_test.csv')\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\ntdf = pd.read_csv(\"./10mar_test.csv\").iloc[:, 1:]\ntdf.head()\n\ntdf.shape\n# Get null values and dataframe information  check for any missing data in data sets\nprint('Null Values In DataFrame: {}\\n'.format(tdf.isna().sum().sum()))\ntdf.info()\ntdf=tdf.fillna(0)\ntdf.to_csv(\"data_fil10.csv\")\n\ntdf\n\n\n\ntestdata = pd.read_csv('./10mar_test.csv').iloc[:, 1:] \n \ntestdata.head(10)\n#testdata=testdata.drop(['16'],axis=1)\ntestdata\n\nprint('Null Values In DataFrame: {}\\n'.format(testdata.isna().sum().sum()))\ntestdata.isnull().sum(0)\n\ntestdata=testdata.fillna(0)\ntestdata\n\n\n\nfrom sklearn.model_selection import train_test_split\n#kfold =sklearn.model_selection.KFold(n_splits=10)\n\nimport pandas as pd\n \nfrom sklearn.metrics import log_loss\n#seed=7\n#\n\n# importing voting classifier\nfrom sklearn.ensemble import VotingClassifier\n \n    \n#Edata10Mar = supp10_data2\nEdata10Mar =testdata \nEdata10Mar\n\nX = Edata10Mar \ny= df_data1[\"class\"] \nX\nfeature_cols = list(X) \ny\n# split data\nX_train, X_test, Y_train, Y_test = train_test_split(X, y)\n\n\n\n\n\nestimators = []\nestimators.append(('c1',clf_dtc2))\nestimators.append(('c2',clf_dtc3))\nestimators.append(('c3',clf_dtc4))\nestimators.append(('c4',clf_dtc5))\n\n\n'''voting = VotingClassifier(estimators=estimators,voting='hard')\nvot_hard=voting.fit(X_train, Y_train)\n\ny_pred=vot_hard.predict(X_test)\nprint(y_pred)\nscore=accuracy_score(Y_test,y_pred)\n#print(\"hard voting score %d\" % score)\nprint(score)'''\n\n\n\n# Voting Classifier with soft voting\nvot_soft = VotingClassifier(estimators = estimators, voting ='soft')\nvot_soft.fit(X_train, Y_train)\ny_pred = vot_soft.predict(X_test)\nprint(y_pred)\n# using accuracy_score\nsscore = accuracy_score(Y_test, y_pred)\n#print(\"Soft Voting Score % d\" % score)\nprint(sscore)\n\nfrom sklearn.metrics import classification_report\n\n#print(classification_report(Y_test, y_pred))\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(Y_test, y_pred)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-08T10:27:25.908025Z","iopub.execute_input":"2024-01-08T10:27:25.908384Z","iopub.status.idle":"2024-01-08T10:27:26.007085Z","shell.execute_reply.started":"2024-01-08T10:27:25.908358Z","shell.execute_reply":"2024-01-08T10:27:26.006111Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluate the DT performance on 10 to 50% of Missing Values \n","metadata":{}},{"cell_type":"code","source":"orig_dataset=df_data1.drop('class',axis=1)\norig_dataset\nimport pandas as pd\nimport missingno as msno\nhar = orig_dataset\n#har1=har.iloc[:,:-1]\nhar1=har\n#msno.heatmap(har1)\n#msno.dendrogram(har1)\nhar1=har1.values\n#print('Shape Test:\\t{}\\n'.format(har1.shape))\nhar1\n\n\nhar1=har1.astype(float)\nhar1\n\nhar1_miss_mar = produce_NA(har1=har1, p_miss=0.50, mecha=\"MAR\", p_obs=0.5)\n \n\n\n#print(har1_mar) \nprint(har1_miss_mar['har1_init'])\nhar1_mar = har1_miss_mar['har1_incomp']\nprint(har1_mar)  \n#har1_mar = pd.DataFrame.from_dict(har1_mar)\nR_mcar = har1_miss_mar['mask']\nprint(R_mcar)\n \n\nprint(\"Percentage of generated missing values: \", (R_mcar.sum()).numpy()/np.prod(R_mcar.size())*100, \" %\")\n\nprint(har1_mar)\nprint('Shape Test:\\t{}\\n'.format(har1_mar.shape))\n\nimport torch\nimport pandas as pd\nimport numpy as np\n\n \nx_np = har1_mar.numpy()\nx_df = pd.DataFrame(x_np)\nx_df.to_csv('10mar_test.csv')\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\ntdf = pd.read_csv(\"./10mar_test.csv\").iloc[:, 1:]\ntdf.head()\n\ntdf.shape\n# Get null values and dataframe information  check for any missing data in data sets\nprint('Null Values In DataFrame: {}\\n'.format(tdf.isna().sum().sum()))\ntdf.info()\ntdf=tdf.fillna(0)\ntdf.to_csv(\"data_fil10.csv\")\n\ntdf\n\n\n\ntestdata = pd.read_csv('./10mar_test.csv').iloc[:, 1:] \n \ntestdata.head(10)\n#testdata=testdata.drop(['16'],axis=1)\ntestdata\n\nprint('Null Values In DataFrame: {}\\n'.format(testdata.isna().sum().sum()))\ntestdata.isnull().sum(0)\n\ntestdata=testdata.fillna(0)\ntestdata\nfrom sklearn.model_selection import train_test_split\n#kfold =sklearn.model_selection.KFold(n_splits=10)\n\nimport pandas as pd\n \nfrom sklearn.metrics import log_loss\n#seed=7\n#\n\n# importing voting classifier\nfrom sklearn.ensemble import VotingClassifier\n \n    \n#Edata10Mar = supp10_data2\nEdata10Mar =testdata \nEdata10Mar\nX = Edata10Mar  \ny= df_data1[\"class\"] \nX\nfeature_cols = list(X) \ny\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = None)\nclf_dtc5 = DecisionTreeClassifier()\nclf_dtc5.fit(X_train, y_train)\nfeature_cols = list(X) \nimport six\nimport sys\nsys.modules['sklearn.externals.six'] = six\n#from six imporaccuracy_scoret StringIO\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\ndot_data = StringIO()\nexport_graphviz(clf_dtc5, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True, feature_names = feature_cols,class_names=['0','1','2'])\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png('ClassifierIoT1.png')\ni=Image(graph.create_png())\ni\n\n\n\ny_pred = clf_dtc5.predict(X_test)\nprint(y_pred)\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T10:38:58.051399Z","iopub.execute_input":"2024-01-08T10:38:58.051794Z","iopub.status.idle":"2024-01-08T10:38:58.721965Z","shell.execute_reply.started":"2024-01-08T10:38:58.051761Z","shell.execute_reply":"2024-01-08T10:38:58.72099Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**","metadata":{}},{"cell_type":"markdown","source":"# Other Classifiers - Performance ","metadata":{}},{"cell_type":"markdown","source":"# 1. SVC","metadata":{}},{"cell_type":"code","source":" ","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"orig_dataset=df_data1.drop('class',axis=1)\norig_dataset\nimport pandas as pd\nimport missingno as msno\nhar = orig_dataset\n#har1=har.iloc[:,:-1]\nhar1=har\n#msno.heatmap(har1)\n#msno.dendrogram(har1)\nhar1=har1.values\n#print('Shape Test:\\t{}\\n'.format(har1.shape))\nhar1\n\n\nhar1=har1.astype(float)\nhar1\n\nhar1_miss_mar = produce_NA(har1=har1, p_miss=0.50, mecha=\"MAR\", p_obs=0.5)\n \n\n\n#print(har1_mar) \nprint(har1_miss_mar['har1_init'])\nhar1_mar = har1_miss_mar['har1_incomp']\nprint(har1_mar)  \n#har1_mar = pd.DataFrame.from_dict(har1_mar)\nR_mcar = har1_miss_mar['mask']\nprint(R_mcar)\n \n\nprint(\"Percentage of generated missing values: \", (R_mcar.sum()).numpy()/np.prod(R_mcar.size())*100, \" %\")\n\nprint(har1_mar)\nprint('Shape Test:\\t{}\\n'.format(har1_mar.shape))\n\nimport torch\nimport pandas as pd\nimport numpy as np\n\n \nx_np = har1_mar.numpy()\nx_df = pd.DataFrame(x_np)\nx_df.to_csv('10mar_test.csv')\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\ntdf = pd.read_csv(\"./10mar_test.csv\").iloc[:, 1:]\ntdf.head()\n\ntdf.shape\n# Get null values and dataframe information  check for any missing data in data sets\nprint('Null Values In DataFrame: {}\\n'.format(tdf.isna().sum().sum()))\ntdf.info()\ntdf=tdf.fillna(0)\ntdf.to_csv(\"data_fil10.csv\")\n\ntdf\n\n\n\ntestdata = pd.read_csv('./10mar_test.csv').iloc[:, 1:] \n \ntestdata.head(10)\n#testdata=testdata.drop(['16'],axis=1)\ntestdata\n\nprint('Null Values In DataFrame: {}\\n'.format(testdata.isna().sum().sum()))\ntestdata.isnull().sum(0)\n\ntestdata=testdata.fillna(0)\ntestdata\nfrom sklearn.model_selection import train_test_split\n#kfold =sklearn.model_selection.KFold(n_splits=10)\n\nimport pandas as pd\n \nfrom sklearn.metrics import log_loss\n#seed=7\n#\n\n# importing voting classifier\nfrom sklearn.ensemble import VotingClassifier\n \n    \n#Edata10Mar = supp10_data2\nEdata10Mar =testdata \nEdata10Mar\nX = Edata10Mar  \ny= df_data1[\"class\"] \nX\nfeature_cols = list(X) \ny\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = None)\n\nclf_dtc5 = svm.SVC(kernel='linear')\nclf_dtc5.fit(X_train, y_train)\n\n#clf_dtc5 = DecisionTreeClassifier()\n#clf_dtc5.fit(X_train, y_train)\n\nfeature_cols = list(X) \n\n\n\n\ny_pred = clf_dtc5.predict(X_test)\nprint(y_pred)\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T10:56:19.366419Z","iopub.execute_input":"2024-01-08T10:56:19.36687Z","iopub.status.idle":"2024-01-08T10:56:28.564615Z","shell.execute_reply.started":"2024-01-08T10:56:19.366838Z","shell.execute_reply":"2024-01-08T10:56:28.563598Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# KNN -Classifier ","metadata":{}},{"cell_type":"code","source":"orig_dataset=df_data1.drop('class',axis=1)\norig_dataset\nimport pandas as pd\nimport missingno as msno\nhar = orig_dataset\n#har1=har.iloc[:,:-1]\nhar1=har\n#msno.heatmap(har1)\n#msno.dendrogram(har1)\nhar1=har1.values\n#print('Shape Test:\\t{}\\n'.format(har1.shape))\nhar1\n\n\nhar1=har1.astype(float)\nhar1\n\nhar1_miss_mar = produce_NA(har1=har1, p_miss=0.50, mecha=\"MAR\", p_obs=0.5)\n \n\n\n#print(har1_mar) \nprint(har1_miss_mar['har1_init'])\nhar1_mar = har1_miss_mar['har1_incomp']\nprint(har1_mar)  \n#har1_mar = pd.DataFrame.from_dict(har1_mar)\nR_mcar = har1_miss_mar['mask']\nprint(R_mcar)\n \n\nprint(\"Percentage of generated missing values: \", (R_mcar.sum()).numpy()/np.prod(R_mcar.size())*100, \" %\")\n\nprint(har1_mar)\nprint('Shape Test:\\t{}\\n'.format(har1_mar.shape))\n\nimport torch\nimport pandas as pd\nimport numpy as np\n\n \nx_np = har1_mar.numpy()\nx_df = pd.DataFrame(x_np)\nx_df.to_csv('10mar_test.csv')\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\ntdf = pd.read_csv(\"./10mar_test.csv\").iloc[:, 1:]\ntdf.head()\n\ntdf.shape\n# Get null values and dataframe information  check for any missing data in data sets\nprint('Null Values In DataFrame: {}\\n'.format(tdf.isna().sum().sum()))\ntdf.info()\ntdf=tdf.fillna(0)\ntdf.to_csv(\"data_fil10.csv\")\n\ntdf\n\n\n\ntestdata = pd.read_csv('./10mar_test.csv').iloc[:, 1:] \n \ntestdata.head(10)\n#testdata=testdata.drop(['16'],axis=1)\ntestdata\n\nprint('Null Values In DataFrame: {}\\n'.format(testdata.isna().sum().sum()))\ntestdata.isnull().sum(0)\n\ntestdata=testdata.fillna(0)\ntestdata\nfrom sklearn.model_selection import train_test_split\n#kfold =sklearn.model_selection.KFold(n_splits=10)\n\nimport pandas as pd\n \nfrom sklearn.metrics import log_loss\n#seed=7\n#\n\n# importing voting classifier\nfrom sklearn.ensemble import VotingClassifier\n \n    \n#Edata10Mar = supp10_data2\nEdata10Mar =testdata \nEdata10Mar\nX = Edata10Mar  \ny= df_data1[\"class\"] \nX\nfeature_cols = list(X) \ny\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = None)\n\nclf_dtc5 = KNeighborsClassifier(n_neighbors=5)\nclf_dtc5.fit(X_train, y_train)\n\n#clf_dtc5 = DecisionTreeClassifier()\n#clf_dtc5.fit(X_train, y_train)\n\nfeature_cols = list(X) \n\n\n\n\ny_pred = clf_dtc5.predict(X_test)\nprint(y_pred)\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T11:02:42.289245Z","iopub.execute_input":"2024-01-08T11:02:42.289624Z","iopub.status.idle":"2024-01-08T11:02:42.378992Z","shell.execute_reply.started":"2024-01-08T11:02:42.289593Z","shell.execute_reply":"2024-01-08T11:02:42.377969Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Random Forest ","metadata":{}},{"cell_type":"code","source":"orig_dataset=df_data1.drop('class',axis=1)\norig_dataset\nimport pandas as pd\nimport missingno as msno\nhar = orig_dataset\n#har1=har.iloc[:,:-1]\nhar1=har\n#msno.heatmap(har1)\n#msno.dendrogram(har1)\nhar1=har1.values\n#print('Shape Test:\\t{}\\n'.format(har1.shape))\nhar1\n\n\nhar1=har1.astype(float)\nhar1\n\nhar1_miss_mar = produce_NA(har1=har1, p_miss=0.10, mecha=\"MAR\", p_obs=0.5)\n \n\n\n#print(har1_mar) \nprint(har1_miss_mar['har1_init'])\nhar1_mar = har1_miss_mar['har1_incomp']\nprint(har1_mar)  \n#har1_mar = pd.DataFrame.from_dict(har1_mar)\nR_mcar = har1_miss_mar['mask']\nprint(R_mcar)\n \n\nprint(\"Percentage of generated missing values: \", (R_mcar.sum()).numpy()/np.prod(R_mcar.size())*100, \" %\")\n\nprint(har1_mar)\nprint('Shape Test:\\t{}\\n'.format(har1_mar.shape))\n\nimport torch\nimport pandas as pd\nimport numpy as np\n\n \nx_np = har1_mar.numpy()\nx_df = pd.DataFrame(x_np)\nx_df.to_csv('10mar_test.csv')\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\ntdf = pd.read_csv(\"./10mar_test.csv\").iloc[:, 1:]\ntdf.head()\n\ntdf.shape\n# Get null values and dataframe information  check for any missing data in data sets\nprint('Null Values In DataFrame: {}\\n'.format(tdf.isna().sum().sum()))\ntdf.info()\ntdf=tdf.fillna(0)\ntdf.to_csv(\"data_fil10.csv\")\n\ntdf\n\n\n\ntestdata = pd.read_csv('./10mar_test.csv').iloc[:, 1:] \n \ntestdata.head(10)\n#testdata=testdata.drop(['16'],axis=1)\ntestdata\n\nprint('Null Values In DataFrame: {}\\n'.format(testdata.isna().sum().sum()))\ntestdata.isnull().sum(0)\n\ntestdata=testdata.fillna(0)\ntestdata\nfrom sklearn.model_selection import train_test_split\n#kfold =sklearn.model_selection.KFold(n_splits=10)\n\nimport pandas as pd\n \nfrom sklearn.metrics import log_loss\n#seed=7\n#\n\n# importing voting classifier\nfrom sklearn.ensemble import VotingClassifier\n \n    \n#Edata10Mar = supp10_data2\nEdata10Mar =testdata \nEdata10Mar\nX = Edata10Mar  \ny= df_data1[\"class\"] \nX\nfeature_cols = list(X) \ny\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = None)\n\nclf_dtc5 = RandomForestClassifier()\nclf_dtc5.fit(X_train, y_train)\n\n#clf_dtc5 = DecisionTreeClassifier()\n#clf_dtc5.fit(X_train, y_train)\n\nfeature_cols = list(X) \n\n\n\n\ny_pred = clf_dtc5.predict(X_test)\nprint(y_pred)\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T11:08:08.231676Z","iopub.execute_input":"2024-01-08T11:08:08.232061Z","iopub.status.idle":"2024-01-08T11:08:08.514635Z","shell.execute_reply.started":"2024-01-08T11:08:08.232031Z","shell.execute_reply":"2024-01-08T11:08:08.513657Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create aSecond Balanced Dataset for exploring the same \n","metadata":{}},{"cell_type":"code","source":"df_datab2=pd.read_csv(\"/kaggle/input/b2-dataset/B2-newmodifieddataset.csv\").iloc[:, 1:]\n\ndf_datab2=df_datab2.fillna(0)\n\ndf_datab2.info()\n\n\nX = df_datab2.drop(\"class\", axis=1)     # everything except 'class' column\ny = df_datab2['class']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = None)\nclf_dtcb21 = DecisionTreeClassifier()\nclf_dtcb21.fit(X_train, y_train)\nfeature_cols = list(X) \nimport six\nimport sys\nsys.modules['sklearn.externals.six'] = six\n#from six imporaccuracy_scoret StringIO\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\ndot_data = StringIO()\nexport_graphviz(clf_dtcb21, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True, feature_names = feature_cols,class_names=['0','1','2'])\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png('ClassifierIoTb21.png')\ni=Image(graph.create_png())\ni\n\n\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-09T05:02:55.977141Z","iopub.execute_input":"2024-01-09T05:02:55.977882Z","iopub.status.idle":"2024-01-09T05:02:56.418517Z","shell.execute_reply.started":"2024-01-09T05:02:55.977822Z","shell.execute_reply":"2024-01-09T05:02:56.41695Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = clf_dtcb21.predict(X_test)\nprint(y_pred)\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T05:03:02.124046Z","iopub.execute_input":"2024-01-09T05:03:02.1245Z","iopub.status.idle":"2024-01-09T05:03:02.155594Z","shell.execute_reply.started":"2024-01-09T05:03:02.124467Z","shell.execute_reply":"2024-01-09T05:03:02.154028Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create a modified Dataset ","metadata":{}},{"cell_type":"code","source":"columns = ['age','blood_pressure','specific_gravity','albumin','sugar',' red_blood_cells','pus_cell','pus_cell_clumps','bacteria','blood_urea',' serum_creatinine ','potassium ','white_blood_cell_count','red_blood_cell_count ','hypertension','diabetes_mellitus ','coronary_artery_disease',' appetite ','anemia','class']\ndatab21 = pd.DataFrame(df_datab2, columns=columns)\ndatab21\ndatab21=datab21.fillna(0)\n\nX = datab21.drop(\"class\", axis=1)     # everything except 'class' column\ny = datab21['class']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = None)\nclf_dtcb22 = DecisionTreeClassifier()\nclf_dtcb22.fit(X_train, y_train)\nfeature_cols = list(X) \nimport six\nimport sys\nsys.modules['sklearn.externals.six'] = six\n#from six imporaccuracy_scoret StringIO\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\ndot_data = StringIO()\nexport_graphviz(clf_dtcb22, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True, feature_names = feature_cols,class_names=['0','1','2'])\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png('ClassifierIoTb22.png')\ni=Image(graph.create_png())\ni","metadata":{"execution":{"iopub.status.busy":"2024-01-09T05:12:34.688941Z","iopub.execute_input":"2024-01-09T05:12:34.689517Z","iopub.status.idle":"2024-01-09T05:12:35.199661Z","shell.execute_reply.started":"2024-01-09T05:12:34.689481Z","shell.execute_reply":"2024-01-09T05:12:35.198197Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ny_pred = clf_dtcb22.predict(X_test)\nprint(y_pred)\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T05:12:41.026096Z","iopub.execute_input":"2024-01-09T05:12:41.026584Z","iopub.status.idle":"2024-01-09T05:12:41.057864Z","shell.execute_reply.started":"2024-01-09T05:12:41.026549Z","shell.execute_reply":"2024-01-09T05:12:41.056647Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modified Dataset ","metadata":{}},{"cell_type":"code","source":"columns = ['sugar',' red_blood_cells','pus_cell','pus_cell_clumps','bacteria','blood_urea',' serum_creatinine ','potassium ','red_blood_cell_count ','diabetes_mellitus ','coronary_artery_disease',' appetite ','anemia','class']\ndatab22 = pd.DataFrame(df_datab2, columns=columns)\ndatab22\ndatab22=datab22.fillna(0)\n\nX = datab22.drop(\"class\", axis=1)     # everything except 'class' column\ny = datab22['class']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = None)\nclf_dtcb23 = DecisionTreeClassifier()\nclf_dtcb23.fit(X_train, y_train)\nfeature_cols = list(X) \nimport six\nimport sys\nsys.modules['sklearn.externals.six'] = six\n#from six imporaccuracy_scoret StringIO\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\ndot_data = StringIO()\nexport_graphviz(clf_dtcb23, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True, feature_names = feature_cols,class_names=['0','1','2'])\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png('ClassifierIoTb23.png')\ni=Image(graph.create_png())\ni\n\n\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-09T05:16:44.276307Z","iopub.execute_input":"2024-01-09T05:16:44.276868Z","iopub.status.idle":"2024-01-09T05:16:46.323426Z","shell.execute_reply.started":"2024-01-09T05:16:44.276829Z","shell.execute_reply":"2024-01-09T05:16:46.322079Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = clf_dtcb23.predict(X_test)\nprint(y_pred)\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T05:16:52.034226Z","iopub.execute_input":"2024-01-09T05:16:52.034668Z","iopub.status.idle":"2024-01-09T05:16:52.065054Z","shell.execute_reply.started":"2024-01-09T05:16:52.034636Z","shell.execute_reply":"2024-01-09T05:16:52.063792Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modified Dataset \n","metadata":{}},{"cell_type":"code","source":"columns = [' red_blood_cells','bacteria',' serum_creatinine ',\n           'potassium ','red_blood_cell_count ','diabetes_mellitus ',\n           'coronary_artery_disease',' appetite ','class']\ndatab23 = pd.DataFrame(df_datab2, columns=columns)\ndatab23\ndatab23=datab23.fillna(0)\n\nX = datab23.drop(\"class\", axis=1)     # everything except 'class' column\ny = datab23['class']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = None)\nclf_dtcb24 = DecisionTreeClassifier()\nclf_dtcb24.fit(X_train, y_train)\nfeature_cols = list(X) \nimport six\nimport sys\nsys.modules['sklearn.externals.six'] = six\n#from six imporaccuracy_scoret StringIO\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\ndot_data = StringIO()\nexport_graphviz(clf_dtcb24, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True, feature_names = feature_cols,class_names=['0','1','2'])\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png('ClassifierIoTb23.png')\ni=Image(graph.create_png())\ni","metadata":{"execution":{"iopub.status.busy":"2024-01-09T05:23:27.787385Z","iopub.execute_input":"2024-01-09T05:23:27.787965Z","iopub.status.idle":"2024-01-09T05:23:28.018476Z","shell.execute_reply.started":"2024-01-09T05:23:27.787928Z","shell.execute_reply":"2024-01-09T05:23:28.017022Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = clf_dtcb24.predict(X_test)\nprint(y_pred)\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(y_test, y_pred)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-09T05:23:32.809088Z","iopub.execute_input":"2024-01-09T05:23:32.809552Z","iopub.status.idle":"2024-01-09T05:23:32.84142Z","shell.execute_reply.started":"2024-01-09T05:23:32.80952Z","shell.execute_reply":"2024-01-09T05:23:32.839572Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modifed dataset \n","metadata":{}},{"cell_type":"code","source":"columns = ['red_blood_cells',' serum_creatinine ','potassium','red_blood_cell_count ','diabetes_mellitus ', 'appetite ','class']\ndatab24 = pd.DataFrame(df_datab2, columns=columns)\ndatab24\ndatab24=datab24.fillna(0)\n\nX = datab24.drop(\"class\", axis=1)     # everything except 'class' column\ny = datab24['class']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = None)\nclf_dtcb25 = DecisionTreeClassifier()\nclf_dtcb25.fit(X_train, y_train)\nfeature_cols = list(X) \nimport six\nimport sys\nsys.modules['sklearn.externals.six'] = six\n#from six imporaccuracy_scoret StringIO\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\ndot_data = StringIO()\nexport_graphviz(clf_dtcb25, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True, feature_names = feature_cols,class_names=['0','1','2'])\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png('ClassifierIoTb23.png')\ni=Image(graph.create_png())\ni\n","metadata":{"execution":{"iopub.status.busy":"2024-01-09T05:26:05.058528Z","iopub.execute_input":"2024-01-09T05:26:05.059567Z","iopub.status.idle":"2024-01-09T05:26:06.463368Z","shell.execute_reply.started":"2024-01-09T05:26:05.059524Z","shell.execute_reply":"2024-01-09T05:26:06.462085Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = clf_dtcb25.predict(X_test)\nprint(y_pred)\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T05:26:20.3421Z","iopub.execute_input":"2024-01-09T05:26:20.342612Z","iopub.status.idle":"2024-01-09T05:26:20.373259Z","shell.execute_reply.started":"2024-01-09T05:26:20.342575Z","shell.execute_reply":"2024-01-09T05:26:20.371736Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modified Dataset ","metadata":{}},{"cell_type":"code","source":"columns = ['serum_creatinine ','red_blood_cell_count ','diabetes_mellitus ','appetite ','class']\ndatab25 = pd.DataFrame(df_datab2, columns=columns)\ndatab25\ndatab25=datab25.fillna(0)\n\nX = datab25.drop(\"class\", axis=1)     # everything except 'class' column\ny = datab25['class']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = None)\nclf_dtcb26 = DecisionTreeClassifier()\nclf_dtcb26.fit(X_train, y_train)\nfeature_cols = list(X) \nimport six\nimport sys\nsys.modules['sklearn.externals.six'] = six\n#from six imporaccuracy_scoret StringIO\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\ndot_data = StringIO()\nexport_graphviz(clf_dtcb26, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True, feature_names = feature_cols,class_names=['0','1','2'])\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png('ClassifierIoTb26.png')\ni=Image(graph.create_png())\ni\n","metadata":{"execution":{"iopub.status.busy":"2024-01-09T05:29:56.346559Z","iopub.execute_input":"2024-01-09T05:29:56.347026Z","iopub.status.idle":"2024-01-09T05:29:56.452842Z","shell.execute_reply.started":"2024-01-09T05:29:56.346992Z","shell.execute_reply":"2024-01-09T05:29:56.451533Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"As no attributes are considered for DT construction we neglect thme ","metadata":{}},{"cell_type":"markdown","source":"# Save B2 Subspace classifiers ","metadata":{}},{"cell_type":"code","source":"import pickle\npickle.dump(clf_dtcb21, open('clf_dtcb21', 'wb'))\nclf_dtcb21 = pickle.load(open('clf_dtcb21', 'rb'))\n#pickled_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T05:35:18.470483Z","iopub.execute_input":"2024-01-09T05:35:18.471797Z","iopub.status.idle":"2024-01-09T05:35:18.481837Z","shell.execute_reply.started":"2024-01-09T05:35:18.471746Z","shell.execute_reply":"2024-01-09T05:35:18.480296Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\npickle.dump(clf_dtcb22, open('clf_dtcb22', 'wb'))\nclf_dtcb22 = pickle.load(open('clf_dtcb22', 'rb'))\n#pickled_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T05:35:39.063415Z","iopub.execute_input":"2024-01-09T05:35:39.06388Z","iopub.status.idle":"2024-01-09T05:35:39.071366Z","shell.execute_reply.started":"2024-01-09T05:35:39.063847Z","shell.execute_reply":"2024-01-09T05:35:39.070188Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\npickle.dump(clf_dtcb23, open('clf_dtcb23', 'wb'))\nclf_dtcb23 = pickle.load(open('clf_dtcb23', 'rb'))\n#pickled_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T05:35:52.717608Z","iopub.execute_input":"2024-01-09T05:35:52.718407Z","iopub.status.idle":"2024-01-09T05:35:52.7298Z","shell.execute_reply.started":"2024-01-09T05:35:52.718358Z","shell.execute_reply":"2024-01-09T05:35:52.727106Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\npickle.dump(clf_dtcb24, open('clf_dtcb24', 'wb'))\nclf_dtcb24 = pickle.load(open('clf_dtcb24', 'rb'))\n#pickled_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T05:36:06.117237Z","iopub.execute_input":"2024-01-09T05:36:06.11779Z","iopub.status.idle":"2024-01-09T05:36:06.128005Z","shell.execute_reply.started":"2024-01-09T05:36:06.117747Z","shell.execute_reply":"2024-01-09T05:36:06.126347Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\npickle.dump(clf_dtcb25, open('clf_dtcb25', 'wb'))\nclf_dtcb25 = pickle.load(open('clf_dtcb25', 'rb'))\n#pickled_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T05:36:21.454599Z","iopub.execute_input":"2024-01-09T05:36:21.455266Z","iopub.status.idle":"2024-01-09T05:36:21.464102Z","shell.execute_reply.started":"2024-01-09T05:36:21.455225Z","shell.execute_reply":"2024-01-09T05:36:21.4625Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Now create a Ensemble classifier for B2 dataset  and test with different percentages of missing values ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport missingno as msno\n\ndf_datab2=pd.read_csv(\"/kaggle/input/b2-dataset/B2-newmodifieddataset.csv\").iloc[:, 1:]\n\ndf_datab2=df_datab2.fillna(0)\n\ndf_datab2.info()\n\n\nhar = df_datab2\n#har1=har.iloc[:,:-1]\nhar1=har\n#msno.heatmap(har1)\n#msno.dendrogram(har1)\nhar1=har1.values\n#print('Shape Test:\\t{}\\n'.format(har1.shape))\nhar1\n\n\nhar1=har1.astype(float)\nhar1\n\n\ndef produce_NA(har1, p_miss, mecha=\"MAR\", opt=\"logistic\", p_obs=None, q=None):\n    to_torch = torch.is_tensor(har1) ## output a pytorch tensor, or a numpy array\n    if not to_torch:\n        har1 = har1.astype(np.float32)\n        har1 = torch.from_numpy(har1)\n    \n    if mecha == \"MAR\" and opt == \"logistic\":\n        mask = MAR_mask(har1, p_miss, p_obs).double()\n        print(\"mask values\")\n        print(mask)\n    elif mecha == \"MNAR\" and opt == \"logistic\":\n        mask = MNAR_mask_logistic(har1, p_miss, p_obs).double()\n    elif mecha == \"MNAR\" and opt == \"quantile\":\n        mask = MNAR_mask_quantiles(har1, p_miss, q, 1-p_obs).double()\n    elif mecha == \"MNAR\" and opt == \"selfmasked\":\n        mask = MNAR_self_mask_logistic(har1, p_miss).double()\n    else:\n        mask = (torch.rand(har1.shape) < p_miss).double()\n     \n    \n    har1_nas = har1.clone()\n    har1_nas[mask.bool()] = np.nan\n    \n    \n    \n    \n    return {'har1_init': har1.double(), 'har1_incomp': har1_nas.double(), 'mask': mask}\n\n\n\nhar1_miss_mar = produce_NA(har1=har1, p_miss=0.10, mecha=\"MAR\", p_obs=0.5)\n \n\n\n#print(har1_mar) \nprint(har1_miss_mar['har1_init'])\nhar1_mar = har1_miss_mar['har1_incomp']\nprint(har1_mar)  \n#har1_mar = pd.DataFrame.from_dict(har1_mar)\nR_mcar = har1_miss_mar['mask']\nprint(R_mcar)\n \n\nprint(\"Percentage of generated missing values: \", (R_mcar.sum()).numpy()/np.prod(R_mcar.size())*100, \" %\")\n\nprint(har1_mar)\nprint('Shape Test:\\t{}\\n'.format(har1_mar.shape))\n\nimport torch\nimport pandas as pd\nimport numpy as np\n\n \nx_np = har1_mar.numpy()\nx_df = pd.DataFrame(x_np)\nx_df.to_csv('10mar_test.csv')\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\ntdf = pd.read_csv(\"./10mar_test.csv\").iloc[:, 1:]\ntdf.head()\n\ntdf.shape\n# Get null values and dataframe information  check for any missing data in data sets\nprint('Null Values In DataFrame: {}\\n'.format(tdf.isna().sum().sum()))\ntdf.info()\ntdf=tdf.fillna(0)\ntdf.to_csv(\"data_fil100.csv\")\n\ntdf\n\n\n\ntestdata = pd.read_csv('./10mar_test.csv').iloc[:, 1:] \n \ntestdata.head(10)\n#testdata=testdata.drop(['16'],axis=1)\ntestdata\n\nprint('Null Values In DataFrame: {}\\n'.format(testdata.isna().sum().sum()))\ntestdata.isnull().sum(0)\n\ntestdata=testdata.fillna(0)\ntestdata\n\n\n\nfrom sklearn.model_selection import train_test_split\n#kfold =sklearn.model_selection.KFold(n_splits=10)\n\nimport pandas as pd\n \nfrom sklearn.metrics import log_loss\n#seed=7\n#\n\n# importing voting classifier\nfrom sklearn.ensemble import VotingClassifier\n \n    \n#Edata10Mar = supp10_data2\nEdata10Mar =testdata \nEdata10Mar\n\nX = Edata10Mar \ny= df_datab2[\"class\"] \nX\nfeature_cols = list(X) \ny\n# split data\nX_train, X_test, Y_train, Y_test = train_test_split(X, y)\n\n\n\n\n\nestimators = []\nestimators.append(('c1',clf_dtcb21))\nestimators.append(('c2',clf_dtcb22))\nestimators.append(('c3',clf_dtcb23))\nestimators.append(('c4',clf_dtcb24))\nestimators.append(('c5',clf_dtcb25))\n\n\n\n'''voting = VotingClassifier(estimators=estimators,voting='hard')\nvot_hard=voting.fit(X_train, Y_train)\n\ny_pred=vot_hard.predict(X_test)\nprint(y_pred)\nscore=accuracy_score(Y_test,y_pred)\n#print(\"hard voting score %d\" % score)\nprint(score)'''\n\n\n\n# Voting Classifier with soft voting\nvot_soft = VotingClassifier(estimators = estimators, voting ='soft')\nvot_soft.fit(X_train, Y_train)\ny_pred = vot_soft.predict(X_test)\nprint(y_pred)\n# using accuracy_score\nsscore = accuracy_score(Y_test, y_pred)\n#print(\"Soft Voting Score % d\" % score)\nprint(sscore)\n\nfrom sklearn.metrics import classification_report\n\n#print(classification_report(Y_test, y_pred))\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(Y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T05:55:25.109796Z","iopub.execute_input":"2024-01-09T05:55:25.110488Z","iopub.status.idle":"2024-01-09T05:55:25.288148Z","shell.execute_reply.started":"2024-01-09T05:55:25.110436Z","shell.execute_reply":"2024-01-09T05:55:25.286613Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport missingno as msno\n\ndf_datab2=pd.read_csv(\"/kaggle/input/b2-dataset/B2-newmodifieddataset.csv\").iloc[:, 1:]\n\ndf_datab2=df_datab2.fillna(0)\n\ndf_datab2.info()\n\n\nhar = df_datab2\n#har1=har.iloc[:,:-1]\nhar1=har\n#msno.heatmap(har1)\n#msno.dendrogram(har1)\nhar1=har1.values\n#print('Shape Test:\\t{}\\n'.format(har1.shape))\nhar1\n\n\nhar1=har1.astype(float)\nhar1\n\n\ndef produce_NA(har1, p_miss, mecha=\"MAR\", opt=\"logistic\", p_obs=None, q=None):\n    to_torch = torch.is_tensor(har1) ## output a pytorch tensor, or a numpy array\n    if not to_torch:\n        har1 = har1.astype(np.float32)\n        har1 = torch.from_numpy(har1)\n    \n    if mecha == \"MAR\" and opt == \"logistic\":\n        mask = MAR_mask(har1, p_miss, p_obs).double()\n        print(\"mask values\")\n        print(mask)\n    elif mecha == \"MNAR\" and opt == \"logistic\":\n        mask = MNAR_mask_logistic(har1, p_miss, p_obs).double()\n    elif mecha == \"MNAR\" and opt == \"quantile\":\n        mask = MNAR_mask_quantiles(har1, p_miss, q, 1-p_obs).double()\n    elif mecha == \"MNAR\" and opt == \"selfmasked\":\n        mask = MNAR_self_mask_logistic(har1, p_miss).double()\n    else:\n        mask = (torch.rand(har1.shape) < p_miss).double()\n     \n    \n    har1_nas = har1.clone()\n    har1_nas[mask.bool()] = np.nan\n    \n    \n    \n    \n    return {'har1_init': har1.double(), 'har1_incomp': har1_nas.double(), 'mask': mask}\n\n\n\nhar1_miss_mar = produce_NA(har1=har1, p_miss=0.20, mecha=\"MAR\", p_obs=0.5)\n \n\n\n#print(har1_mar) \nprint(har1_miss_mar['har1_init'])\nhar1_mar = har1_miss_mar['har1_incomp']\nprint(har1_mar)  \n#har1_mar = pd.DataFrame.from_dict(har1_mar)\nR_mcar = har1_miss_mar['mask']\nprint(R_mcar)\n \n\nprint(\"Percentage of generated missing values: \", (R_mcar.sum()).numpy()/np.prod(R_mcar.size())*100, \" %\")\n\nprint(har1_mar)\nprint('Shape Test:\\t{}\\n'.format(har1_mar.shape))\n\nimport torch\nimport pandas as pd\nimport numpy as np\n\n \nx_np = har1_mar.numpy()\nx_df = pd.DataFrame(x_np)\nx_df.to_csv('10mar_test.csv')\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\ntdf = pd.read_csv(\"./10mar_test.csv\").iloc[:, 1:]\ntdf.head()\n\ntdf.shape\n# Get null values and dataframe information  check for any missing data in data sets\nprint('Null Values In DataFrame: {}\\n'.format(tdf.isna().sum().sum()))\ntdf.info()\ntdf=tdf.fillna(0)\ntdf.to_csv(\"data_fil100.csv\")\n\ntdf\n\n\n\ntestdata = pd.read_csv('./10mar_test.csv').iloc[:, 1:] \n \ntestdata.head(10)\n#testdata=testdata.drop(['16'],axis=1)\ntestdata\n\nprint('Null Values In DataFrame: {}\\n'.format(testdata.isna().sum().sum()))\ntestdata.isnull().sum(0)\n\ntestdata=testdata.fillna(0)\ntestdata\n\n\n\nfrom sklearn.model_selection import train_test_split\n#kfold =sklearn.model_selection.KFold(n_splits=10)\n\nimport pandas as pd\n \nfrom sklearn.metrics import log_loss\n#seed=7\n#\n\n# importing voting classifier\nfrom sklearn.ensemble import VotingClassifier\n \n    \n#Edata10Mar = supp10_data2\nEdata10Mar =testdata \nEdata10Mar\n\nX = Edata10Mar \ny= df_datab2[\"class\"] \nX\nfeature_cols = list(X) \ny\n# split data\nX_train, X_test, Y_train, Y_test = train_test_split(X, y)\n\n\n\n\n\nestimators = []\nestimators.append(('c1',clf_dtcb21))\nestimators.append(('c2',clf_dtcb22))\nestimators.append(('c3',clf_dtcb23))\nestimators.append(('c4',clf_dtcb24))\nestimators.append(('c5',clf_dtcb25))\n\n\n\n'''voting = VotingClassifier(estimators=estimators,voting='hard')\nvot_hard=voting.fit(X_train, Y_train)\n\ny_pred=vot_hard.predict(X_test)\nprint(y_pred)\nscore=accuracy_score(Y_test,y_pred)\n#print(\"hard voting score %d\" % score)\nprint(score)'''\n\n\n\n# Voting Classifier with soft voting\nvot_soft = VotingClassifier(estimators = estimators, voting ='soft')\nvot_soft.fit(X_train, Y_train)\ny_pred = vot_soft.predict(X_test)\nprint(y_pred)\n# using accuracy_score\nsscore = accuracy_score(Y_test, y_pred)\n#print(\"Soft Voting Score % d\" % score)\nprint(sscore)\n\nfrom sklearn.metrics import classification_report\n\n#print(classification_report(Y_test, y_pred))\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(Y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T06:01:13.775118Z","iopub.execute_input":"2024-01-09T06:01:13.7757Z","iopub.status.idle":"2024-01-09T06:01:13.945867Z","shell.execute_reply.started":"2024-01-09T06:01:13.77566Z","shell.execute_reply":"2024-01-09T06:01:13.943962Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport missingno as msno\n\ndf_datab2=pd.read_csv(\"/kaggle/input/b2-dataset/B2-newmodifieddataset.csv\").iloc[:, 1:]\n\ndf_datab2=df_datab2.fillna(0)\n\ndf_datab2.info()\n\n\nhar = df_datab2\n#har1=har.iloc[:,:-1]\nhar1=har\n#msno.heatmap(har1)\n#msno.dendrogram(har1)\nhar1=har1.values\n#print('Shape Test:\\t{}\\n'.format(har1.shape))\nhar1\n\n\nhar1=har1.astype(float)\nhar1\n\n\ndef produce_NA(har1, p_miss, mecha=\"MAR\", opt=\"logistic\", p_obs=None, q=None):\n    to_torch = torch.is_tensor(har1) ## output a pytorch tensor, or a numpy array\n    if not to_torch:\n        har1 = har1.astype(np.float32)\n        har1 = torch.from_numpy(har1)\n    \n    if mecha == \"MAR\" and opt == \"logistic\":\n        mask = MAR_mask(har1, p_miss, p_obs).double()\n        print(\"mask values\")\n        print(mask)\n    elif mecha == \"MNAR\" and opt == \"logistic\":\n        mask = MNAR_mask_logistic(har1, p_miss, p_obs).double()\n    elif mecha == \"MNAR\" and opt == \"quantile\":\n        mask = MNAR_mask_quantiles(har1, p_miss, q, 1-p_obs).double()\n    elif mecha == \"MNAR\" and opt == \"selfmasked\":\n        mask = MNAR_self_mask_logistic(har1, p_miss).double()\n    else:\n        mask = (torch.rand(har1.shape) < p_miss).double()\n     \n    \n    har1_nas = har1.clone()\n    har1_nas[mask.bool()] = np.nan\n    \n    \n    \n    \n    return {'har1_init': har1.double(), 'har1_incomp': har1_nas.double(), 'mask': mask}\n\n\n\nhar1_miss_mar = produce_NA(har1=har1, p_miss=0.30, mecha=\"MAR\", p_obs=0.5)\n \n\n\n#print(har1_mar) \nprint(har1_miss_mar['har1_init'])\nhar1_mar = har1_miss_mar['har1_incomp']\nprint(har1_mar)  \n#har1_mar = pd.DataFrame.from_dict(har1_mar)\nR_mcar = har1_miss_mar['mask']\nprint(R_mcar)\n \n\nprint(\"Percentage of generated missing values: \", (R_mcar.sum()).numpy()/np.prod(R_mcar.size())*100, \" %\")\n\nprint(har1_mar)\nprint('Shape Test:\\t{}\\n'.format(har1_mar.shape))\n\nimport torch\nimport pandas as pd\nimport numpy as np\n\n \nx_np = har1_mar.numpy()\nx_df = pd.DataFrame(x_np)\nx_df.to_csv('10mar_test.csv')\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\ntdf = pd.read_csv(\"./10mar_test.csv\").iloc[:, 1:]\ntdf.head()\n\ntdf.shape\n# Get null values and dataframe information  check for any missing data in data sets\nprint('Null Values In DataFrame: {}\\n'.format(tdf.isna().sum().sum()))\ntdf.info()\ntdf=tdf.fillna(0)\ntdf.to_csv(\"data_fil100.csv\")\n\ntdf\n\n\n\ntestdata = pd.read_csv('./10mar_test.csv').iloc[:, 1:] \n \ntestdata.head(10)\n#testdata=testdata.drop(['16'],axis=1)\ntestdata\n\nprint('Null Values In DataFrame: {}\\n'.format(testdata.isna().sum().sum()))\ntestdata.isnull().sum(0)\n\ntestdata=testdata.fillna(0)\ntestdata\n\n\n\nfrom sklearn.model_selection import train_test_split\n#kfold =sklearn.model_selection.KFold(n_splits=10)\n\nimport pandas as pd\n \nfrom sklearn.metrics import log_loss\n#seed=7\n#\n\n# importing voting classifier\nfrom sklearn.ensemble import VotingClassifier\n \n    \n#Edata10Mar = supp10_data2\nEdata10Mar =testdata \nEdata10Mar\n\nX = Edata10Mar \ny= df_datab2[\"class\"] \nX\nfeature_cols = list(X) \ny\n# split data\nX_train, X_test, Y_train, Y_test = train_test_split(X, y)\n\n\n\n\n\nestimators = []\nestimators.append(('c1',clf_dtcb21))\nestimators.append(('c2',clf_dtcb22))\nestimators.append(('c3',clf_dtcb23))\nestimators.append(('c4',clf_dtcb24))\nestimators.append(('c5',clf_dtcb25))\n\n\n\n'''voting = VotingClassifier(estimators=estimators,voting='hard')\nvot_hard=voting.fit(X_train, Y_train)\n\ny_pred=vot_hard.predict(X_test)\nprint(y_pred)\nscore=accuracy_score(Y_test,y_pred)\n#print(\"hard voting score %d\" % score)\nprint(score)'''\n\n\n\n# Voting Classifier with soft voting\nvot_soft = VotingClassifier(estimators = estimators, voting ='soft')\nvot_soft.fit(X_train, Y_train)\ny_pred = vot_soft.predict(X_test)\nprint(y_pred)\n# using accuracy_score\nsscore = accuracy_score(Y_test, y_pred)\n#print(\"Soft Voting Score % d\" % score)\nprint(sscore)\n\nfrom sklearn.metrics import classification_report\n\n#print(classification_report(Y_test, y_pred))\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(Y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T06:02:01.73459Z","iopub.execute_input":"2024-01-09T06:02:01.735082Z","iopub.status.idle":"2024-01-09T06:02:01.891561Z","shell.execute_reply.started":"2024-01-09T06:02:01.735049Z","shell.execute_reply":"2024-01-09T06:02:01.890346Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport missingno as msno\n\ndf_datab2=pd.read_csv(\"/kaggle/input/b2-dataset/B2-newmodifieddataset.csv\").iloc[:, 1:]\n\ndf_datab2=df_datab2.fillna(0)\n\ndf_datab2.info()\n\n\nhar = df_datab2\n#har1=har.iloc[:,:-1]\nhar1=har\n#msno.heatmap(har1)\n#msno.dendrogram(har1)\nhar1=har1.values\n#print('Shape Test:\\t{}\\n'.format(har1.shape))\nhar1\n\n\nhar1=har1.astype(float)\nhar1\n\n\ndef produce_NA(har1, p_miss, mecha=\"MAR\", opt=\"logistic\", p_obs=None, q=None):\n    to_torch = torch.is_tensor(har1) ## output a pytorch tensor, or a numpy array\n    if not to_torch:\n        har1 = har1.astype(np.float32)\n        har1 = torch.from_numpy(har1)\n    \n    if mecha == \"MAR\" and opt == \"logistic\":\n        mask = MAR_mask(har1, p_miss, p_obs).double()\n        print(\"mask values\")\n        print(mask)\n    elif mecha == \"MNAR\" and opt == \"logistic\":\n        mask = MNAR_mask_logistic(har1, p_miss, p_obs).double()\n    elif mecha == \"MNAR\" and opt == \"quantile\":\n        mask = MNAR_mask_quantiles(har1, p_miss, q, 1-p_obs).double()\n    elif mecha == \"MNAR\" and opt == \"selfmasked\":\n        mask = MNAR_self_mask_logistic(har1, p_miss).double()\n    else:\n        mask = (torch.rand(har1.shape) < p_miss).double()\n     \n    \n    har1_nas = har1.clone()\n    har1_nas[mask.bool()] = np.nan\n    \n    \n    \n    \n    return {'har1_init': har1.double(), 'har1_incomp': har1_nas.double(), 'mask': mask}\n\n\n\nhar1_miss_mar = produce_NA(har1=har1, p_miss=0.40, mecha=\"MAR\", p_obs=0.5)\n \n\n\n#print(har1_mar) \nprint(har1_miss_mar['har1_init'])\nhar1_mar = har1_miss_mar['har1_incomp']\nprint(har1_mar)  \n#har1_mar = pd.DataFrame.from_dict(har1_mar)\nR_mcar = har1_miss_mar['mask']\nprint(R_mcar)\n \n\nprint(\"Percentage of generated missing values: \", (R_mcar.sum()).numpy()/np.prod(R_mcar.size())*100, \" %\")\n\nprint(har1_mar)\nprint('Shape Test:\\t{}\\n'.format(har1_mar.shape))\n\nimport torch\nimport pandas as pd\nimport numpy as np\n\n \nx_np = har1_mar.numpy()\nx_df = pd.DataFrame(x_np)\nx_df.to_csv('10mar_test.csv')\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\ntdf = pd.read_csv(\"./10mar_test.csv\").iloc[:, 1:]\ntdf.head()\n\ntdf.shape\n# Get null values and dataframe information  check for any missing data in data sets\nprint('Null Values In DataFrame: {}\\n'.format(tdf.isna().sum().sum()))\ntdf.info()\ntdf=tdf.fillna(0)\ntdf.to_csv(\"data_fil100.csv\")\n\ntdf\n\n\n\ntestdata = pd.read_csv('./10mar_test.csv').iloc[:, 1:] \n \ntestdata.head(10)\n#testdata=testdata.drop(['16'],axis=1)\ntestdata\n\nprint('Null Values In DataFrame: {}\\n'.format(testdata.isna().sum().sum()))\ntestdata.isnull().sum(0)\n\ntestdata=testdata.fillna(0)\ntestdata\n\n\n\nfrom sklearn.model_selection import train_test_split\n#kfold =sklearn.model_selection.KFold(n_splits=10)\n\nimport pandas as pd\n \nfrom sklearn.metrics import log_loss\n#seed=7\n#\n\n# importing voting classifier\nfrom sklearn.ensemble import VotingClassifier\n \n    \n#Edata10Mar = supp10_data2\nEdata10Mar =testdata \nEdata10Mar\n\nX = Edata10Mar \ny= df_datab2[\"class\"] \nX\nfeature_cols = list(X) \ny\n# split data\nX_train, X_test, Y_train, Y_test = train_test_split(X, y)\n\n\n\n\n\nestimators = []\nestimators.append(('c1',clf_dtcb21))\nestimators.append(('c2',clf_dtcb22))\nestimators.append(('c3',clf_dtcb23))\nestimators.append(('c4',clf_dtcb24))\nestimators.append(('c5',clf_dtcb25))\n\n\n\n'''voting = VotingClassifier(estimators=estimators,voting='hard')\nvot_hard=voting.fit(X_train, Y_train)\n\ny_pred=vot_hard.predict(X_test)\nprint(y_pred)\nscore=accuracy_score(Y_test,y_pred)\n#print(\"hard voting score %d\" % score)\nprint(score)'''\n\n\n\n# Voting Classifier with soft voting\nvot_soft = VotingClassifier(estimators = estimators, voting ='soft')\nvot_soft.fit(X_train, Y_train)\ny_pred = vot_soft.predict(X_test)\nprint(y_pred)\n# using accuracy_score\nsscore = accuracy_score(Y_test, y_pred)\n#print(\"Soft Voting Score % d\" % score)\nprint(sscore)\n\nfrom sklearn.metrics import classification_report\n\n#print(classification_report(Y_test, y_pred))\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(Y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T06:02:16.476685Z","iopub.execute_input":"2024-01-09T06:02:16.477182Z","iopub.status.idle":"2024-01-09T06:02:16.631424Z","shell.execute_reply.started":"2024-01-09T06:02:16.477146Z","shell.execute_reply":"2024-01-09T06:02:16.630249Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport missingno as msno\n\ndf_datab2=pd.read_csv(\"/kaggle/input/b2-dataset/B2-newmodifieddataset.csv\").iloc[:, 1:]\n\ndf_datab2=df_datab2.fillna(0)\n\ndf_datab2.info()\n\n\nhar = df_datab2\n#har1=har.iloc[:,:-1]\nhar1=har\n#msno.heatmap(har1)\n#msno.dendrogram(har1)\nhar1=har1.values\n#print('Shape Test:\\t{}\\n'.format(har1.shape))\nhar1\n\n\nhar1=har1.astype(float)\nhar1\n\n\ndef produce_NA(har1, p_miss, mecha=\"MAR\", opt=\"logistic\", p_obs=None, q=None):\n    to_torch = torch.is_tensor(har1) ## output a pytorch tensor, or a numpy array\n    if not to_torch:\n        har1 = har1.astype(np.float32)\n        har1 = torch.from_numpy(har1)\n    \n    if mecha == \"MAR\" and opt == \"logistic\":\n        mask = MAR_mask(har1, p_miss, p_obs).double()\n        print(\"mask values\")\n        print(mask)\n    elif mecha == \"MNAR\" and opt == \"logistic\":\n        mask = MNAR_mask_logistic(har1, p_miss, p_obs).double()\n    elif mecha == \"MNAR\" and opt == \"quantile\":\n        mask = MNAR_mask_quantiles(har1, p_miss, q, 1-p_obs).double()\n    elif mecha == \"MNAR\" and opt == \"selfmasked\":\n        mask = MNAR_self_mask_logistic(har1, p_miss).double()\n    else:\n        mask = (torch.rand(har1.shape) < p_miss).double()\n     \n    \n    har1_nas = har1.clone()\n    har1_nas[mask.bool()] = np.nan\n    \n    \n    \n    \n    return {'har1_init': har1.double(), 'har1_incomp': har1_nas.double(), 'mask': mask}\n\n\n\nhar1_miss_mar = produce_NA(har1=har1, p_miss=0.50, mecha=\"MAR\", p_obs=0.5)\n \n\n\n#print(har1_mar) \nprint(har1_miss_mar['har1_init'])\nhar1_mar = har1_miss_mar['har1_incomp']\nprint(har1_mar)  \n#har1_mar = pd.DataFrame.from_dict(har1_mar)\nR_mcar = har1_miss_mar['mask']\nprint(R_mcar)\n \n\nprint(\"Percentage of generated missing values: \", (R_mcar.sum()).numpy()/np.prod(R_mcar.size())*100, \" %\")\n\nprint(har1_mar)\nprint('Shape Test:\\t{}\\n'.format(har1_mar.shape))\n\nimport torch\nimport pandas as pd\nimport numpy as np\n\n \nx_np = har1_mar.numpy()\nx_df = pd.DataFrame(x_np)\nx_df.to_csv('10mar_test.csv')\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\ntdf = pd.read_csv(\"./10mar_test.csv\").iloc[:, 1:]\ntdf.head()\n\ntdf.shape\n# Get null values and dataframe information  check for any missing data in data sets\nprint('Null Values In DataFrame: {}\\n'.format(tdf.isna().sum().sum()))\ntdf.info()\ntdf=tdf.fillna(0)\ntdf.to_csv(\"data_fil100.csv\")\n\ntdf\n\n\n\ntestdata = pd.read_csv('./10mar_test.csv').iloc[:, 1:] \n \ntestdata.head(10)\n#testdata=testdata.drop(['16'],axis=1)\ntestdata\n\nprint('Null Values In DataFrame: {}\\n'.format(testdata.isna().sum().sum()))\ntestdata.isnull().sum(0)\n\ntestdata=testdata.fillna(0)\ntestdata\n\n\n\nfrom sklearn.model_selection import train_test_split\n#kfold =sklearn.model_selection.KFold(n_splits=10)\n\nimport pandas as pd\n \nfrom sklearn.metrics import log_loss\n#seed=7\n#\n\n# importing voting classifier\nfrom sklearn.ensemble import VotingClassifier\n \n    \n#Edata10Mar = supp10_data2\nEdata10Mar =testdata \nEdata10Mar\n\nX = Edata10Mar \ny= df_datab2[\"class\"] \nX\nfeature_cols = list(X) \ny\n# split data\nX_train, X_test, Y_train, Y_test = train_test_split(X, y)\n\n\n\n\n\nestimators = []\nestimators.append(('c1',clf_dtcb21))\nestimators.append(('c2',clf_dtcb22))\nestimators.append(('c3',clf_dtcb23))\nestimators.append(('c4',clf_dtcb24))\nestimators.append(('c5',clf_dtcb25))\n\n\n\n'''voting = VotingClassifier(estimators=estimators,voting='hard')\nvot_hard=voting.fit(X_train, Y_train)\n\ny_pred=vot_hard.predict(X_test)\nprint(y_pred)\nscore=accuracy_score(Y_test,y_pred)\n#print(\"hard voting score %d\" % score)\nprint(score)'''\n\n\n\n# Voting Classifier with soft voting\nvot_soft = VotingClassifier(estimators = estimators, voting ='soft')\nvot_soft.fit(X_train, Y_train)\ny_pred = vot_soft.predict(X_test)\nprint(y_pred)\n# using accuracy_score\nsscore = accuracy_score(Y_test, y_pred)\n#print(\"Soft Voting Score % d\" % score)\nprint(sscore)\n\nfrom sklearn.metrics import classification_report\n\n#print(classification_report(Y_test, y_pred))\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(Y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T06:02:31.938676Z","iopub.execute_input":"2024-01-09T06:02:31.93928Z","iopub.status.idle":"2024-01-09T06:02:32.095295Z","shell.execute_reply.started":"2024-01-09T06:02:31.939242Z","shell.execute_reply":"2024-01-09T06:02:32.094065Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Now Lets combine both the balanced datasets EC's and make EC of EC and test with different percentages of missing values \n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport missingno as msno\n\ndf_datab2=pd.read_csv(\"/kaggle/input/actual-after-preprocesing-datast/actual-newmodifieddataset.csv\").iloc[:, 1:]\n\ndf_datab2=df_datab2.fillna(0)\n\ndf_datab2.info()\n\n\nhar = df_datab2\n#har1=har.iloc[:,:-1]\nhar1=har\n#msno.heatmap(har1)\n#msno.dendrogram(har1)\nhar1=har1.values\n#print('Shape Test:\\t{}\\n'.format(har1.shape))\nhar1\n\n\nhar1=har1.astype(float)\nhar1\n\n\ndef produce_NA(har1, p_miss, mecha=\"MAR\", opt=\"logistic\", p_obs=None, q=None):\n    to_torch = torch.is_tensor(har1) ## output a pytorch tensor, or a numpy array\n    if not to_torch:\n        har1 = har1.astype(np.float32)\n        har1 = torch.from_numpy(har1)\n    \n    if mecha == \"MAR\" and opt == \"logistic\":\n        mask = MAR_mask(har1, p_miss, p_obs).double()\n        print(\"mask values\")\n        print(mask)\n    elif mecha == \"MNAR\" and opt == \"logistic\":\n        mask = MNAR_mask_logistic(har1, p_miss, p_obs).double()\n    elif mecha == \"MNAR\" and opt == \"quantile\":\n        mask = MNAR_mask_quantiles(har1, p_miss, q, 1-p_obs).double()\n    elif mecha == \"MNAR\" and opt == \"selfmasked\":\n        mask = MNAR_self_mask_logistic(har1, p_miss).double()\n    else:\n        mask = (torch.rand(har1.shape) < p_miss).double()\n     \n    \n    har1_nas = har1.clone()\n    har1_nas[mask.bool()] = np.nan\n    \n    \n    \n    \n    return {'har1_init': har1.double(), 'har1_incomp': har1_nas.double(), 'mask': mask}\n\n\n\nhar1_miss_mar = produce_NA(har1=har1, p_miss=0.40, mecha=\"MAR\", p_obs=0.5)\n \n\n\n#print(har1_mar) \nprint(har1_miss_mar['har1_init'])\nhar1_mar = har1_miss_mar['har1_incomp']\nprint(har1_mar)  \n#har1_mar = pd.DataFrame.from_dict(har1_mar)\nR_mcar = har1_miss_mar['mask']\nprint(R_mcar)\n \n\nprint(\"Percentage of generated missing values: \", (R_mcar.sum()).numpy()/np.prod(R_mcar.size())*100, \" %\")\n\nprint(har1_mar)\nprint('Shape Test:\\t{}\\n'.format(har1_mar.shape))\n\nimport torch\nimport pandas as pd\nimport numpy as np\n\n \nx_np = har1_mar.numpy()\nx_df = pd.DataFrame(x_np)\nx_df.to_csv('10mar_test.csv')\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\ntdf = pd.read_csv(\"./10mar_test.csv\").iloc[:, 1:]\ntdf.head()\n\ntdf.shape\n# Get null values and dataframe information  check for any missing data in data sets\nprint('Null Values In DataFrame: {}\\n'.format(tdf.isna().sum().sum()))\ntdf.info()\ntdf=tdf.fillna(0)\ntdf.to_csv(\"data_fil100.csv\")\n\ntdf\n\n\n\ntestdata = pd.read_csv('./10mar_test.csv').iloc[:, 1:] \n \ntestdata.head(10)\n#testdata=testdata.drop(['16'],axis=1)\ntestdata\n\nprint('Null Values In DataFrame: {}\\n'.format(testdata.isna().sum().sum()))\ntestdata.isnull().sum(0)\n\ntestdata=testdata.fillna(0)\ntestdata\n\n\n\nfrom sklearn.model_selection import train_test_split\n#kfold =sklearn.model_selection.KFold(n_splits=10)\n\nimport pandas as pd\n \nfrom sklearn.metrics import log_loss\n#seed=7\n#\n\n# importing voting classifier\nfrom sklearn.ensemble import VotingClassifier\n \n    \n#Edata10Mar = supp10_data2\nEdata10Mar =testdata \nEdata10Mar\n\nX = Edata10Mar \ny= df_datab2[\"class\"] \nX\nfeature_cols = list(X) \ny\n# split data\nX_train, X_test, Y_train, Y_test = train_test_split(X, y)\n\n\n\n\n\nestimators = []\nestimators.append(('c1',clf_dtc2))\nestimators.append(('c2',clf_dtc3))\nestimators.append(('c3',clf_dtc4))\nestimators.append(('c4',clf_dtc5))\nestimators.append(('c5',clf_dtcb21))\nestimators.append(('c6',clf_dtcb22))\nestimators.append(('c7',clf_dtcb23))\nestimators.append(('c8',clf_dtcb24))\nestimators.append(('c9',clf_dtcb25))\n\n\n\n'''voting = VotingClassifier(estimators=estimators,voting='hard')\nvot_hard=voting.fit(X_train, Y_train)\n\ny_pred=vot_hard.predict(X_test)\nprint(y_pred)\nscore=accuracy_score(Y_test,y_pred)\n#print(\"hard voting score %d\" % score)\nprint(score)'''\n\n\n\n# Voting Classifier with soft voting\nvot_soft = VotingClassifier(estimators = estimators, voting ='soft')\nvot_soft.fit(X_train, Y_train)\ny_pred = vot_soft.predict(X_test)\nprint(y_pred)\n# using accuracy_score\nsscore = accuracy_score(Y_test, y_pred)\n#print(\"Soft Voting Score % d\" % score)\nprint(sscore)\n\nfrom sklearn.metrics import classification_report\n\n#print(classification_report(Y_test, y_pred))\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(Y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T06:12:49.003695Z","iopub.execute_input":"2024-01-09T06:12:49.004202Z","iopub.status.idle":"2024-01-09T06:12:49.22421Z","shell.execute_reply.started":"2024-01-09T06:12:49.00417Z","shell.execute_reply":"2024-01-09T06:12:49.222833Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Now apply other classifiers on the actual data ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport missingno as msno\n\ndf_datab2=pd.read_csv(\"/kaggle/input/actual-after-preprocesing-datast/actual-newmodifieddataset.csv\").iloc[:, 1:]\n\ndf_datab2=df_datab2.fillna(0)\n\ndf_datab2.info()\n\norig_dataset=df_datab2.drop('class',axis=1)\norig_dataset\nimport pandas as pd\nimport missingno as msno\nhar = orig_dataset\n#har1=har.iloc[:,:-1]\nhar1=har\n#msno.heatmap(har1)\n#msno.dendrogram(har1)\nhar1=har1.values\n#print('Shape Test:\\t{}\\n'.format(har1.shape))\nhar1\n\n\nhar1=har1.astype(float)\nhar1\n\nhar1_miss_mar = produce_NA(har1=har1, p_miss=0.10, mecha=\"MAR\", p_obs=0.5)\n \n\n\n#print(har1_mar) \nprint(har1_miss_mar['har1_init'])\nhar1_mar = har1_miss_mar['har1_incomp']\nprint(har1_mar)  \n#har1_mar = pd.DataFrame.from_dict(har1_mar)\nR_mcar = har1_miss_mar['mask']\nprint(R_mcar)\n \n\nprint(\"Percentage of generated missing values: \", (R_mcar.sum()).numpy()/np.prod(R_mcar.size())*100, \" %\")\n\nprint(har1_mar)\nprint('Shape Test:\\t{}\\n'.format(har1_mar.shape))\n\nimport torch\nimport pandas as pd\nimport numpy as np\n\n \nx_np = har1_mar.numpy()\nx_df = pd.DataFrame(x_np)\nx_df.to_csv('10mar_test.csv')\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\ntdf = pd.read_csv(\"./10mar_test.csv\").iloc[:, 1:]\ntdf.head()\n\ntdf.shape\n# Get null values and dataframe information  check for any missing data in data sets\nprint('Null Values In DataFrame: {}\\n'.format(tdf.isna().sum().sum()))\ntdf.info()\ntdf=tdf.fillna(0)\ntdf.to_csv(\"data_fil10.csv\")\n\ntdf\n\n\n\ntestdata = pd.read_csv('./10mar_test.csv').iloc[:, 1:] \n \ntestdata.head(10)\n#testdata=testdata.drop(['16'],axis=1)\ntestdata\n\nprint('Null Values In DataFrame: {}\\n'.format(testdata.isna().sum().sum()))\ntestdata.isnull().sum(0)\n\ntestdata=testdata.fillna(0)\ntestdata\nfrom sklearn.model_selection import train_test_split\n#kfold =sklearn.model_selection.KFold(n_splits=10)\n\nimport pandas as pd\n \nfrom sklearn.metrics import log_loss\n#seed=7\n#\n\n# importing voting classifier\nfrom sklearn.ensemble import VotingClassifier\n \n    \n#Edata10Mar = supp10_data2\nEdata10Mar =testdata \nEdata10Mar\nX = Edata10Mar  \ny= df_datab2[\"class\"] \nX\nfeature_cols = list(X) \ny\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = None)\n\nclf_dtc5 = DecisionTreeClassifier()\nclf_dtc5.fit(X_train, y_train)\n\n#clf_dtc5 = DecisionTreeClassifier()\n#clf_dtc5.fit(X_train, y_train)\n\nfeature_cols = list(X) \n\n\n\n\ny_pred = clf_dtc5.predict(X_test)\nprint(y_pred)\ndef Model_Performance(test,pred):\n    #precision = precision_score(test,pred)\n    precision = precision_score(test,pred,average='macro')\n    recall = recall_score(test,pred,average='macro')\n    f1 = f1_score(test,pred,average='macro')\n    #print('1. Confusion Matrix:\\n',confusion_matrix(test, pred))\n    print(\"\\n2. Accuracy Score:\", round(accuracy_score(test, pred)*100,2),\"%\")\n    print(\"3. Precision:\", round(precision*100,2),\"%\")\n    print(\"4. Recall:\",round(recall*100,2),\"%\" )\n    print(\"5. F1 Score:\",round(f1*100,2),\"%\" )\n    print(\"6. clasification report:\\n\",classification_report(test, pred))\nModel_Performance(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T06:58:21.867055Z","iopub.execute_input":"2024-01-09T06:58:21.867552Z","iopub.status.idle":"2024-01-09T06:58:22.021522Z","shell.execute_reply.started":"2024-01-09T06:58:21.867515Z","shell.execute_reply":"2024-01-09T06:58:22.019725Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}